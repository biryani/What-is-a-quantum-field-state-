%\documentclass[twocolumn,lengthcheck,superscriptaddress]{revtex4-1}

\documentclass[11pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epstopdf}
\usepackage{mathrsfs}
\usepackage{enumerate}
\usepackage{xypic}
\usepackage[shortalphabetic]{amsrefs}

\usepackage{hyperref}

\newcommand{\red}[1]{\textcolor{red}{#1}}

\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\vspan}{span}
\DeclareMathOperator{\res}{res}

\theoremstyle{plain}% default
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{corollary}{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}

%\bibliographystyle{amsalpha}

\title{What is a quantum field state?}
\date{\today}                                           % Activate to display a given date or no date


\begin{document}

\begin{abstract} 
There has been in a fruitful interplay of ideas between quantum information theory and high energy physics, especially in the context of quantum simulation, the AdS/CFT correspondence, and the black hole information loss paradox. However, a core difficulty faced by quantum information theorists -- who are usually concerned with qubits -- interested in these emergent and vibrant areas is the necessity of dealing with quantum fields. The primary purpose of these notes is to lower the entry barrier for quantum information theorists to work on these topics by explaining what, in a quantum information friendly way, a quantum field state actually is. We describe the Wilsonian formulation of quantum field theory as an effective theory and explain how this leads naturally to a definition, independent of lagrangians, of quantum field states which is better adapted to, e.g., tensor networks. We hope that there is something here for high-energy theorists as well, if only to see how someone from ``the other side'' thinks about complex quantum systems.
\end{abstract}

\maketitle

\section{Introduction}
Quantum field theory (QFT) has become, thanks to Wilson 
\cite{wilson_renormalization_1974,wilson_renormalization_1975}, an immensely powerful calculational machine to study a wide variety of physical problems from the fundamental physics of particles \cite{peskin_introduction_1995,weinberg_quantum_1996,weinberg_quantum_1996-1,weinberg_quantum_2000} to many body interacting quantum systems such as magnets and dilute atomic gases \cite{fradkin_field_2013}. It is no exaggeration to say that QFT is the calculus of modern physics \cite{witten_surface_2006,seiberg_nathan_2014}. In contrast to the mature status that calculus enjoys, however, QFT is still far from a stable formulation \cite{howard_georgi_particles_2012,moore_physical_2014,seiberg_nathan_2014} as texts on the subject are not standardised and, further,  mathematicians are not yet universally happy with QFT as practiced by physicists. 

Amongst the many formulations of QFT, a most popular one is in terms of \emph{lagrangians}. Here one begins with a set of \emph{classical} equations of motion, encapsulated by a lagrangian via the principle of least action \cite{arnold_mathematical_1989}, and then seeks a \emph{quantisation} of these equations of motion, typically via the path integral prescription. This approach has led to great progress: for example, it works extremely well in the perturbative setting, where quantum field theory is on firm footing and, more importantly, it also provides an elegant way to approach the \emph{nonperturbative} setting where, e.g., it serves as the basis of lattice gauge theory \cite{creutz_quarks_1985,wilson_confinement_1974}. In the case of lattice gauge theory a dramatic validation of the path integral formulation was recently obtained when the hadronic spectrum of QCD was numerically obtained from first principles \cite{durr_ab_2008}. However, despite the power and ubiquity of the lagrangian/path integral approach, there are still many mysteries concerning nonperturbative QFT.  

One way to make progress on understanding nonperturbative QFT might be to eschew the lagrangian parametrisation altogether. This is not a new idea: in the '60s and '70s the idea of deriving all of physics from the analyticity properties \cite{eden_analytic_2002} of the $S$ matrix was very popular. This idea lost steam\footnote{This is actually not fair: the $S$ matrix bootstrap programme was one of the starting points for string theory, which has subsequently enjoyed tremendous success in understanding QFT, especially via dualities. This is a vast topic which lies beyond the scope of these notes. Here we largely focus on non-string approaches to QFT.} in the late '70s in the wake of the stunning success of the standard model. Recently, however, there has been an upswing in interest in formulations of QFT without the lagrangian. A major impetus here comes from string theory \cite{moore_physical_2014,howard_georgi_particles_2012} where there are arguments that there exist certain quantum field theories \cite{witten_comments_1995,moore_lecture_2012} with no known, or no unique, lagrangian. Additional motivation for studying QFT without lagrangians has been powerfully articulated by Arkani-Hamed and collaborators in the course of a programme to understand the scattering amplitudes for $\mathcal{N}=4$ supersymmetric Yang-Mills theory \cite{arkani-hamed_what_2010,arkani-hamed_into_2014,arkani-hamed_tree_2008,arkani-hamed_scattering_2012,arkani-hamed_all-loop_2011,arkani-hamed_amplituhedron_2014,arkani-hamed_s-matrix_2010,arkani-hamed_what_2010}: here the core motivation is to find a parametrisation of QFT which exposes hidden symmetries at the expense of  manifest unitarity and locality, i.e., to allow spacetime to be an emergent property.  

The theme of emergent spacetime plays a crucial role in discussions of the \emph{holographic principle} \cite{bousso_holographic_2002}. In the specific context of the AdS/CFT correspondence \cite{maldacena_large_1999} we have seen that spacetimes of certain associated bulk degrees of freedom are encoded in the hilbert spaces of strongly interacting quantum many body systems living on spatial boundaries. The nature of this encoding is still not completely understood, particularly away from the large-$N$ limit where semiclassical arguments are no longer valid. However, this idea has proved to be so deep that even just taking aim in its general direction has lead to spectacular and exciting progress. Most relevant for this paper is a line of enquiry beginning with the work of Swingle \cite{swingle_entanglement_2012} applying tensor networks to quantify the nature of, and the correspondence between, bulk and boundary degrees of freedom \cite{nozaki_holographic_2012,ryu_aspects_2006,ryu_holographic_2006}. Also closely related, are studies exploiting quantum information theoretic ideas, particularly from the study of quantum error correcting codes \cite{almheiri_bulk_2014,pastawski_holographic_2015} and quantum Shannon theory \cite{czech_information_2014}, aimed at elucidating the interpretation of AdS/CFT duality. These recent studies usually work by first discretisating the problem and then deploying the apparatus of quantum information theory to the resulting discrete system. The precise way in which results obtained in this way survive the limit to the continuum is rather subtle.

Continuing with the themes of holography, emergent spacetime geometry, and quantum information theory, there has been a recent flurry of activity centred around the ``firewall'' paradox, initiated by the work of \cite{almheiri_black_2013}. The ensuing debate has prompted many intriguing and original ideas aimed at resolving the paradox. One extremely suggestive proposal \cite{maldacena_cool_2013}, known as ``ER=EPR'', posits that the fabric of spacetime itself is none other than quantum entanglement. This is heady stuff! However it is hard, especially for the quantum information theorist, to make concrete sense of it, especially since at first sight the proposal appears to be a category error. 

We believe that quantum information theorists have interesting things to contribute to high energy physics, and see several possible avenues forward. The most direct way would be to develop ideas and results that have already proved successful in the study of strongly correlated complex quantum systems to apply to settings of direct interest in high energy physics. In this context, new variational families of \emph{tensor network states} (TNS), including, the \emph{projected entangled pair states} (PEPS) \cite{verstraete_renormalization_2004} and the \emph{multiscale entanglement renormalisation ansatz} (MERA) \cite{vidal_entanglement_2007,vidal_class_2008} could be exploited. The crucial idea underlying these developments is that TNS provide a parsimonious and expressive \emph{data structure} to parametrise  the hilbert space of physical states naturally arising \cite{poulin_quantum_2011} in local quantum systems \cite{orus_practical_2014, haegeman_geometry_2014,osborne_simulating_2007,bravyi_topological_2010,bravyi_short_2011,hastings_lieb-schultz-mattis_2004,hastings_area_2007,osborne_efficient_2006}. One way to carry out the goal of understanding quantum fields via tensor network methods is to formulate TNS directly in the continuum. This approach has already given rise to the continuous matrix products states (cMPS) \cite{verstraete_continuous_2010,osborne_holographic_2010, haegeman_calculus_2013}, continuous PEPS \cite{jennings_variational_2012}, and continuous MERA classes \cite{haegeman_entanglement_2013}. Such continuous TNS have provided some new insights in the study of some problems in high-energy physics, and promise to provide a powerful way to reason about entangled quantum fields. Another way, adopted in this paper, is to simply understand how discrete TNS approximate a given QFT. This approach is easier to implement numerically, and also more directly allows the computation of, e.g., quantum entanglement.

Another avenue where quantum information theory seems likely to lead to progress in high energy physics is by exploiting quantum computers to directly simulate scattering processes. This is an important goal, even in the perturbative setting, because quantum computers allow the computation of scattering amplitudes involving many particles requiring the summation of a prohibitive number of Feynman diagrams. Pursuit of this idea has led to the development of discrete quantum simulation algorithms for scalar field theory \cite{jordan_quantum_2012,jordan_quantum_2011} and the Gross-Neveu model on the lattice \cite{jordan_quantum_2014}. Here there are again fascinating questions about how to understand the nonperturbative regime and the approach to the continuum.  

Finally, and somewhat more speculatively, the work \cite{arkani-hamed_what_2010,arkani-hamed_into_2014,arkani-hamed_tree_2008,arkani-hamed_scattering_2012,arkani-hamed_all-loop_2011,arkani-hamed_amplituhedron_2014,arkani-hamed_s-matrix_2010,arkani-hamed_what_2010} of Arkani-Hamed and collaborators is rather suggestive to someone with a quantum information background: the idea that scattering amplitudes can be directly obtained from the volumes of a certain special convex set known as the \emph{amplituhedron} resonates strongly with themes that have been discussed in the quantum information literature. In particular, the amplituhedron bears a superficial resemblence to the convex set of reduced density operators for (translation invariant) complex quantum systems \cite{verstraete_matrix_2006,zauner_symmetry_2014}. For instance, one can argue that scattering amplitudes for any complex quantum system may be directly derived from knowledge of a related convex set \cite{osborne_tobiasosborne}. Whether the connection between these two topics is more than metaphoric is far from clear, however, it seems like a deep idea worth exploring further. 

So it seems that there are a variety of ways in which quantum information theory could contribute to high energy theory. However, there is a fundamental difficulty facing the quantum information theorist:  quantum fields involve a continuous infinity of degrees of freedom, a setting rather far removed from the home ground of quantum information theory, namely, the qubit. Faced with the insecurity of exploring such unfamiliar territory it is tempting to work from a comfortable rigourous mathematical formulation. However,  a satisfying universally accepted mathematical framework for QFT has yet to be found; there are a panoply of existing approaches from the algebraic, probabilistic, to the geometric (we are lucky in that we can simply refer to an excellent recent survey of Douglas \cite{douglas_foundations_2012}, who provides a broad overview of the existing approaches to a mathematical theory of QFT). It is certainly possible that quantum information theory could contribute to high energy physics via one of the aforementioned mathematical approaches. However, we now end up with two problems, namely, understanding and developing quantum information ideas for a given mathematical approach, and then working out how to apply them to physical problems. 

The approach adopted in these notes is rather different. Here we advocate directly understanding QFT as practiced by physicists. This differs in two important ways from most of the existing mathematical approaches that have been so far developed. Firstly, we regard QFT as an \emph{effective theory} and, secondly, we focus on quantum \emph{state space} in addition to quantum observables. By understanding the way QFT is formulated as an effective theory, we can avoid a lot of heavy mathematical machinery and get down to concrete problems and calculations. 

So what is a quantum field state? Our answer is that it is a \emph{sequence of states} of discretised theories with a certain property, namely, that each term gets closer to each other (i.e., a \emph{Cauchy sequence}). This is directly analogous to how we study, via computer, classical fields, like fluids and gases and the electromagnetic field. Following in the footsteps of Wilson, we spend some time discussing how to measure ``closeness'', leading to the introduction of a family of quantum information distance measures quantifying the large-scale behaviour of a quantum many body state. 

We've structured this paper as follows. We begin in \S\ref{sec:opqp} with a short overview of operational quantum mechanics with an emphasis on density operators, completely positive maps, and POVMs. After setting up this basic language we move on in \S\ref{sec:quant} to a short overview of the problems of quantisation. Then we discuss in \S\ref{sec:whatisqft}, on a purely heuristic level, what a field theory really ought to be. With this motivation in hand we then discuss effective theories in \S\ref{sec:effectivetheories}, which directly leads to the Wilsonian formulation of effective quantum field theory, reviewed in \S\ref{sec:wilson}. This discussion is then used as the direct motivation for our definition of effective quantum field states in \S\ref{sec:effectiveqftstates}. The construction of quantum field states via completion is then introduced in \S\ref{sec:qftcompletion}. The explanation of the renormalisation group as a means to construct Cauchy sequences of states is then described in \S\ref{sec:cauchyseqrg}. Finally, we conclude with some discussion and outlook in \S\ref{sec:discussion}.

\section{Operational quantum physics}\label{sec:opqp}
Throughout these notes we emphasise the \emph{operational} or \emph{modular}\footnote{Modular refers, in this context, to the idea that the primitive operations of preparation, evolution, and measurement may be composed arbitrarily to build \emph{quantum circuits}, much as we do in building classical circuits.} \emph{viewpoint}: here the focus is on physical quantities with an \emph{operational interpretation}, i.e., a physical quantity is considered operationally meaningful only if there exists, at least in principle, an experiment which could measure it. The modular viewpoint is common within the quantum information community as it lends itself very naturally to the discussion of quantum circuits. The operational view also seems to mesh rather well with the Wilsonian view of QFT, where QFT is seen as an effective theory.

A convenient way to discuss quantum physics within the operational or modular viewpoint is via \emph{observables and effects}, \emph{density operators}, and \emph{completely positive maps} \cite{ludwig_foundations_1983,davies_quantum_1976}. This language may be unfamiliar to the reader and we pause a moment to review it here. Firstly, the way we characterise \emph{quantum} (indeed, also \emph{classical}) systems is via a set $\mathcal{A}$ of \emph{observables}. The observables typically form an algebra isomorphic to the bounded operators $\mathcal{B}(\mathcal{H})$ on some hilbert space $\mathcal{H}$, although this is not necessary\footnote{The algebra structure is usually employed as a proxy for \emph{positivity}. All that we actually need is that $\mathcal{A}$ is an \emph{Archmidean Order Unit} (AOU) vector space \cite{paulsen_vector_2009,kleinmann_typical_2013}.} for there to be a probability interpretation. For the probability interpretation we need only require that $\mathcal{A}$ has a notion of \emph{positivity}, i.e., there is a cone $\mathcal{A}^+ \subset \mathcal{A}$ of positive elements and that there is a distinguished unit element $\mathbb{I}\in\mathcal{A}$ which is also positive. A good example to keep in mind here is that of the \emph{qubit}, where $\mathcal{A}\equiv M_2(\mathbb{C})$, the algebra of $2\times 2$ complex matrices and $\mathcal{A}^+ \equiv \{M\in \mathcal{A}\,|\, M\ge 0\}$ (with $\ge$ denoting the positive semidefinite order, i.e., $M\ge 0$ if and only if there exists $A\in \mathcal{A}$ such that $M = A^\dag A$). Another example is that of a \emph{classical} system, which is characterised by a \emph{commutative algebra} $\mathcal{A}\equiv \mathcal{C}(X)$, the set of functions from some set $X$ to $\mathbb{C}$; a \emph{classical bit} corresponds to the choice $X \equiv \{0,1\}$. An \emph{effect} $E\in\mathcal{A}^+$ is then what we call an observable corresponding to an \emph{outcome}, \emph{proposition}, \emph{predicate}, or \emph{yes/no measurement}. It is characterised by the property that $0\le E\le \mathbb{I}$. The unit element is the effect corresponding to the empty predicate, that is, no assertion. For the qubit example above the projector $P_0 = \left(\begin{smallmatrix} 1 & 0 \\ 0 & 0\end{smallmatrix}\right)$ is the effect corresponding to the assertion that the system is in the ``zero'' configuration. A POVM\footnote{The acronym POVM stands for ``positive operator valued measure'', which takes its full meaning when the observable can take a continuous sets of values. } corresponds to a measurement of a system and---provided it can take only finitely many values---comprises of a set $\mathcal{M} = \{E_j\}_{j=1}^n$ of effects such that 
\begin{equation}
	\sum_{j=1}^n E_j = \mathbb{I}.
\end{equation}
The subscript label $j$ is what carries the information about what \emph{outcome} was observed when the measurement took place. It can be interpreted directly as the \emph{value} of the observable being measured, or simply as a label of that value. It is worth stressing that the effects $E_j$ need not be projections. Traditionally we speak of hermitian operators as observables in quantum mechanics, but what is actually meant when we declare that the hermitian operator $M = \sum_{j=1}^n m_j E_j$ is an ``observable'' is that we implement the corresponding POVM  $\mathcal{M} = \{E_j\}_{j=1}^n$, where $E_j$ are the spectral projections for $M$. The expectation value $\langle M \rangle$ corresponds to the first moment of the probability distribution determined by $\mathcal{M}$.

Quantum composition of systems is described via the \emph{tensor product} operation: suppose we have two systems $A$ and $B$ characterised by the observable sets $\mathcal{A}_A$ and $\mathcal{A}_B$, respectively. The joint system $AB$ is then characterised by the observable set $\mathcal{A}_{AB} \equiv \mathcal{A}_A\otimes \mathcal{A}_B$. This space allows the simultaneous observation of effects in both $\mathcal{A}_A$ \emph{and} $\mathcal{A}_B$. The \emph{classical composition} of two systems $\mathcal{A}_A$ and $\mathcal{A}_B$, where we allow the observations of effects in \emph{either}  $\mathcal{A}_A$ \emph{or} $\mathcal{A}_B$, i.e., our system is either of one type or another, is described by the \emph{direct sum} operation $\mathcal{A}_{A}\oplus \mathcal{A}_B$. This is the smallest space of effects allowing us to probabilistically measure an effect from  $\mathcal{A}_A$ or $\mathcal{A}_B$.

A \emph{state} $\omega:\mathcal{A}\rightarrow \mathbb{C}$ on the observable set $\mathcal{A}$ is a \emph{positive}, \emph{normalised}, and \emph{linear} functional, i.e., $\omega:\mathcal{A}^+\rightarrow \mathbb{R}^+$ and $\omega(e) = 1$. A state describes a \emph{preparation} of the system, and captures all the information relevant for the statistical outcomes of measurements on the system. The probability $p_E$ that, after a measurement of a POVM $\mathcal{M}$, an outcome with corresponding effect $E$ occurs is given by $p_E = \omega(E)$. Usually in quantum information theory we work with finite-dimensional quantum systems with $\mathcal{A}\equiv M_d(\mathbb{C})$ so that we can represent states via \emph{density operators} $\rho\in M_d(\mathbb{C})$ according to $\omega(M) \equiv \tr(\rho M)$, with $\tr(\rho) = 1$, $\rho \ge 0$. (Be aware that in infinite-dimensional settings it is not always possible to find a density operator corresponding to a state as the trace condition can easily fail.) A state $\omega$ is \emph{pure} if it cannot be written as a convex combination of other states, i.e., if $\omega \not= p \omega' + (1-p) \omega''$, with $p\in (0,1)$. Continuing the qubit example from above we see that single-qubit states $\omega$ correspond to $2\times 2$ density operators 
\begin{equation}
	\rho = \frac{\mathbb{I} + \mathbf{r}\cdot \boldsymbol{\sigma}}{2},  
\end{equation}  
with $\boldsymbol{\sigma} \equiv \left[\left(\begin{smallmatrix} 0 & 1 \\ 1 & 0\end{smallmatrix}\right), \left(\begin{smallmatrix} 0 & -i \\ i & 0\end{smallmatrix}\right), \left(\begin{smallmatrix} 1 & 0 \\ 0 & -1\end{smallmatrix}\right)\right]$. We have that $\omega(\sigma^j) = \tr(\rho \sigma^j)$. The condition that $\rho$ corresponds to a state translates to the condition that $|\mathbf{r}| \le 1$. Pure qubit states are precisely those with $|\mathbf{r}| = 1$.

The most general dynamical process that can occur within quantum mechanics is represented by a \emph{completely positive map} (CP map), or \emph{channel}. These processes describe everything from preparations, time evolutions, measurements, to the addition of ancilla and the discarding of subsystems. The input and output of a CP map may be arbitrary: there is no especial difficulty in the formulation caused by, e.g., different numbers of input and output systems. We first describe CP maps in the \emph{heisenberg picture} where modifications of measurements are specified. Here a CP map $\mathcal{E}$ is characterised by the following three axioms: 
\begin{enumerate}
	\item it is a \emph{linear} map $\mathcal{E}:\mathcal{A}_B\rightarrow \mathcal{A}_A$ from the observables $\mathcal{A}_B$ of an \emph{output system} $B$ to the observables of $\mathcal{A}_A$ of the  \emph{input system} $A$;
	\item the map $\mathcal{E}$ is \emph{positive}, i.e., it takes positive elements to positive elements according to $\mathcal{E}:\mathcal{A}_B^+\rightarrow \mathcal{A}_A^+$; and 
	\item running the map $\mathcal{E}$ in parallel with the \emph{identity channel} $\mathcal{I}_E : \mathcal{A}_E\rightarrow \mathcal{A}_E$ on an arbitrary auxiliary system $\mathcal{A}_E$ yields a positive linear map $\mathcal{E}\otimes \mathcal{I}_E$ from $\mathcal{A}_B\otimes \mathcal{A}_E$ to $\mathcal{A}_A\otimes \mathcal{A}_E$.
\end{enumerate} 
Pleasingly this axiomatic characterisation of a general dynamical process matches the following constructive characterisation. Suppose we only allow maps which comprise of the following three primitives: (1) adjunction of  ancillary systems; (2) unitary transformations; and (3) reduction to a subsystem. Then it is a result of Stinespring that such operations correspond precisely to CP maps and vice versa. 
\begin{theorem}[Stinespring] Suppose that $\mathcal{A}_A \equiv M_m(\mathbb{C})$ and $\mathcal{A}_B \equiv M_n(\mathbb{C})$. Then a linear map $\mathcal{E}:\mathcal{A}_B\rightarrow \mathcal{A}_A$ is completely positive if an only if there is an auxiliary system $\mathcal{A}_E \equiv M_l(\mathbb{C})$ such that it takes the form
\begin{equation}
	\mathcal{E}(X) = V^\dag (X\otimes \mathbb{I}_E) V,
\end{equation}
where $V$ is an operator from $\mathbb{C}^m$ to $\mathbb{C}^n\otimes\mathbb{C}^l$. Further, $V$ is an isometry whenever $\mathcal{E}$ is \emph{unital}, i.e., $\mathcal{E}(\mathbb{I}) = \mathbb{I}$. 
\end{theorem}
Here $V$ describes both the unitary dynamics and the reduction to a subsystem and $X\mapsto X\otimes \mathbb{I}$ describes the adjunction of the ancillary system. 

There are several key examples of CP maps naturally arising in physics.  The first examples are the so-called \emph{cq channels} (cq = classical-quantum), describing \emph{preparations}: these are channels from a set of quantum observables $\mathcal{A}$ to classical observables $\mathcal{C}(X)$ with $X \equiv \{1,2,\ldots, n\}$,
\begin{equation}
	\mathcal{E}(E) \equiv \sum_{j = 1}^n \omega_j (E) \delta_j,
\end{equation}
where $\{\omega_j\}_1^{n}$ are a set of states on $\mathcal{A}$, and $\delta_j$ is the delta function on $\{1,2,\ldots, n\}$, i.e., $\delta_j(k) = \delta_{jk}$. 

The second important subclass of channels are those describing \emph{evolutions} according to \emph{unitary dynamics}: these CP maps are nothing more that conjugation by a unitary operator $U$
\begin{equation}
	\mathcal{U}(X) \equiv U^\dag X U.
\end{equation}

The final essential example of a channel is the \emph{qc channel} describing a POVM measurement
\begin{equation}
	\mathcal{M}(\delta_j) \equiv E_j.
\end{equation}

Using channels we can expose the modular structure of general processes in quantum mechanics, where components can be combined and concatenated: we draw classical information with a double line and quantum states with a single line. The passage of time is thought of as flowing from left to right. Channels are represented as boxes with input and output lines. Accordingly, any experiment in physics ultimately corresponds to the combination of a preparation, an evolution, and a measurement. We represent this pictorially represented as follows.
\begin{center}
\includegraphics{prepevolvemeasure.pdf}
\end{center}
Here, conditioned on a classical input with the value $j$, a quantum state $\rho_j$ is prepared. This is subsequently evolved according to a completely positive map $\mathcal{E}$. Finally a POVM measurement $\mathcal{M} = \{E_k\}$ is performed producing the classical output $k$. Although this modular view of quantum mechanics won't be directly exploited in the sequel, it is present in our minds when we come to discussing the building blocks of quantum field theory. 


Thus, from now on, when we say the word ``theory'' we take this to mean the specification of a triple $(\mathcal{A}, \mathcal{E}_t, \omega)$ of an observable set $\mathcal{A}$, a family of CP maps $\mathcal{E}_t: \mathbb{R}\times\mathcal{A}\rightarrow \mathcal{A}$ of possible evolutions, and a preparation $\omega$. We think of $\mathcal{A}$ as the space of \emph{equal-time} observables. The channel $\mathcal{E}_t$ is what implements the operation of translation in \emph{time}\footnote{In the case where the theory admits an action of a larger group $G$ of, say, spacetime translations, or Poincar\'e transformations, we then suppose that $\mathcal{E}_g$ is indexed by elements of $g\in G$.}. It is convenient to exploit the shorthand notation $A(t) \equiv \mathcal{E}_t(A)$. Thus we can now discuss observables corresponding to measurements at different times. In the case where $\mathcal{A}$ has an algebraic structure\footnote{In the case where $\mathcal{A}$ does not have an algebraic structure we have to explicitly describe correlation functions via instruments.} this allows us to introduce the observables corresponding to $n$-point correlation functions, namely, 
\begin{equation}
	A_1^\dag(t_1)A_2^\dag(t_2)\cdots A_n^\dag(t_n)A_n(t_n) \cdots A_2(t_2)A_1(t_1),
\end{equation} 
where $A_j(t_j) \in \mathcal{A}$, $j= 1,2, \ldots, n$. If $\omega$ is a state represented with density operator $\rho$ on $\mathcal{A}$ the resulting correlator is
\begin{multline}
	\langle A_1^\dag(t_1)A_2^\dag(t_2)\cdots A_n^\dag(t_n)A_n(t_n) \cdots A_2(t_2)A_1(t_1) \rangle =\\ \tr( A_n(t_n) \cdots A_2(t_2)A_1(t_1)\rho A_1^\dag(t_1) A_2^\dag(t_2) \cdots A_n^\dag(t_n)).
\end{multline}
This correlator may be implemented via postselection on the instrument carrying out the measurement of $A_j(t_j)$. 
Note that a ``standard'' $n$-point correlation function $\langle A_n(t_n) \cdots A_2(t_2)A_1(t_1) \rangle$ is not directly measurable in quantum mechanics as, in general, the product $A_n(t_n) \cdots A_2(t_2)A_1(t_1)$ is not even hermitian. Instead, such correlators must be inferred from scattering \cite{taylor_scattering_2006} or interference experiments \cite{glauber_quantum_1963,mandel_optical_1995}.

\section{Quantisation isn't a mystery, it's an inverse problem}\label{sec:quant}
Before we get started with quantum field states we pause a moment to stress a simple yet important point: the universe didn't become quantum in 1927 at the Fifth Solvay International Conference, it has always been quantum. The reason that we didn't notice quantum effects for such a long time is because of \emph{decoherence} \cite{joos_decoherence_2003,gardiner_quantum_2010}, i.e., the unavoidable loss of quantum coherence due to uncontrolled interactions with unobservable environment degrees of freedom. In the presence of quantum noise pure unitary dynamics described by a unitary channel $\mathcal{U}_t$ obeying 
\begin{equation}
	\frac{d}{dt}\mathcal{U}_t(X) \equiv -i [H, \mathcal{U}_t(X)]
\end{equation}
is modified \cite{davies_quantum_1976} to a noisy CP map $\mathcal{E}_t$ generated by 
\begin{equation}
	\frac{d}{dt}\mathcal{E}_t(X) \equiv -i [H, \mathcal{E}_t(X)] -\frac12\sum_{\alpha=1}^m L_\alpha^\dag L_\alpha \mathcal{E}_t(X) + \mathcal{E}_t(X) L_\alpha^\dag L_\alpha - 2 L_\alpha \mathcal{E}_t(X) L_\alpha^\dag
\end{equation}
which can, for quantum systems with a continuous degree of freedom (e.g., a particle on the line), usually be \emph{very effectively} modelled by a symplectic transformation on a classical phase space. 
\begin{center}
\includegraphics{Decoherence.pdf}
\end{center}
The map, induced by decoherence, between a unitary quantum process and an effective classical process is extremely nonlinear and complicated. However, the most relevant feature of decoherence for this discussion is simply that many different quantum dynamical processes can be, after decoherence has set in, effectively modelled by the \emph{same} classical dynamical system. Thus the decoherence map is, amongst other things, a \emph{many to one} map. Thus, when presented with a given classical dynamical system we have no way, not even in principle, of identifying the ``correct'' quantisation; we are trying to invert a many to one map and there is no canonical choice of preimage.  None of this is really surprising or controversial. (Note that the \emph{semiclassical limit} is \emph{not} the same as the \emph{effective classical limit} arising from the presence of decoherence. While there is, in both cases, an emergence of classicality from a quantum system, the reasoning is totally different.)

Quantisation is hard precisely because we are trying to simultaneously solve more than one problem at once: we are trying to find a quantum system such that when we solve the system in the presence of decoherence, we find it is well described by a classical effective theory which matches the originally specified classical system. Said this way it is truly a miracle that the bewildering variety of quantisation recipes developed over the past decades work at all! 
\begin{center}
\includegraphics{Quantisation.pdf}
\end{center}
From this perspective it isn't so surprising that quantisation prescriptions aren't universal maps between classical systems and quantum systems, i.e., in mathematical language, \emph{functors}. 

So how is the inverse problem of quantisation solved? A vitally important role guiding us toward a solution is played by \emph{symmetries}: if a desired classical limit is invariant under some group of symmetry operations then it is reasonable to assume that a good quantisation ought to furnish some representation of the same symmetry group (especially if the envisaged decoherence process leading to the classical limit is not expected to break the symmetry). This radically cuts down the search space we need to cover in looking for a quantisation. It can turn out, however, that the full symmetry group cannot be represented in a given quantisation, in which case we say that one or more symmetries are \emph{anomolous}. It is an interesting question whether, in general, anomolies disappear in the classical limit under a reasonable model of decoherence.

In the more modular language promoted in these notes we simply simplistically regard decoherence as a channel $\mathcal{D}$ that gets applied to our system before we perform our measurements. Thus, in the heisenberg picture, you can think of decoherence as modifying the effects we can measure to more noisy effects.  

\section{What is a field theory}\label{sec:whatisqft}
We begin our discussion by contemplating, at a purely heuristic level, what a \emph{field theory} should be. On a purely intuitive level, a \emph{field} (either quantum or classical) comprises \emph{continuously} many degrees of freedom, i.e., roughly speaking, there is a degree of freedom for each point in space $\mathbb{R}^d$ (or spacetime $\mathbb{R}\times \mathbb{R}^d$). When dealing with such a vast abundance of degrees of freedom the task of just specifying a state of such a field becomes deeply nontrivial. 

Classically, this task is largely solved by calculus. Here \emph{pure field states} can be simply defined to be continuous functions $\phi:\mathbb{R}^d\rightarrow \mathbb{R}$. The space $C(\mathbb{R}^D)$ (or, in the case of spacetime, $C(\mathbb{R}\times\mathbb{R}^D)$) of all \emph{mathematically} possible such field states is rather wild -- it contains fractal monsters -- but not all of the states in $C(\mathbb{R}^D)$ are meant to be \emph{physically realisable}. Classically we specify physical pure states by requiring that they satisfy certain differential equations. For example, in a $(1+1)$-dimensional spacetime of points $(t,x)\in \mathbb{R}^2$ we could demand that valid physical states satisfy
\begin{equation}
	\frac{\partial^2\phi}{\partial t^2} - \frac{\partial^2\phi}{\partial x^2} + m^2\phi = 0.
\end{equation}
Just to be a solution of such an equation of motion implicitly requires that $\phi$ is at least twice differentiable. (Leaving aside, for the moment, the topic of weak solutions and distributions.) The condition of differentiability is actually rather nontrivial as it means that at small scales any solution is quite boring (it is basically a straight line) when we zoom in:
\begin{center}
\includegraphics{difffunc.pdf}
\end{center}
While this doesn't help us solve the problem of building statistical theories of classical fields -- the task of understanding probability measures on infinite dimensional spaces is deeply nontrivial -- it does at least allow us to tame the problem of understanding pure states and their dynamics for systems of continuously many classical degrees of freedom.

But what about quantum theories? Here we encounter a fundamentally new problem not present in the classical case: it is now hard to even define \emph{pure} field states. Naively this should be straightforward: just define the space of pure states to be the tensor product
\begin{equation}
	\mathcal{H}\, \text{``$=$''} \bigotimes_{x\in \mathbb{R}^d} \mathcal{H}_x,
\end{equation}
where $\mathcal{H}_x$ is the hilbert space for a single degree of freedom located at $x$. The scare quotes here are intended to indicate that the object on the right hand side does not \emph{naively} exist in any satisfying mathematical way\footnote{It does exist in a less naive way via von Neumann's incomplete tensor product. The incomplete tensor product admits an attractive physical intepretation: it is the separable hilbert space describing the configurations of at most a finite number of particles above the vacuum state. Finite can mean, e.g., $10^{34}$. This doesn't help us, however, as it just pushes our difficulties into building the vacuum.}. But let us be bold physicists for a moment and simply pretend that mathematicians will sort it all out and the space does exist. In this case we ought to have a basis of pure states labelled, e.g., by continuous functions
\begin{equation}
	\{|\phi\rangle \}_{\phi:\mathbb{R}^d\rightarrow \mathbb{R}}.
\end{equation}
While this initially looks reasonable we quickly find a new problem: what superpositions are we going to allow? All of them? Surely not: we must find equations that specify for us the physically realisable states. Here we can no longer take recourse to calculus for help. Indeed, the problem of specifying physically realisable pure states of quantum fields is intimately tied to the problem of writing probability measures for classical fields in one lower spatial dimension via the so called ``classical-quantum'' correspondence where the path integral for a system in $D$ spatial dimensions can be regarded, via Wick rotation, as defining a statistical mechanical system in $D+1$ euclidean dimensions.

In both the classical statistical field and the quantum field cases we have come up against a fundamental physical problem (as opposed to a technical mathematical problem), namely that of specifying interesting states of fields (in the former case, as probability measures, and in the latter as pure states). What we ideally want is a physical principle that tells what are the ``good'', or \emph{physical}, field states versus the ``bad'', or \emph{unphysical}, states.  

\section{Effective field theories}\label{sec:effectivetheories}

Suppose we have some extraordinarily complicated system of many particles -- a good example to keep in mind is \emph{water}. Now if it were easy, \emph{at no cost}, for us to make any conceivable measurement on the system allowed by quantum mechanics, then there is \emph{no way} we'd be fooled into thinking water is anything other than a collection of a vast number of fundamental particles, quarks, gluons, etc., in some incredibly complicated evolving entangled state. The reason we don't see water like this is that we \emph{can't} make any measurement of the system without paying some kind of bill: the more complicated the measurement, the more we have to pay. Thus we have to settle with making measurements of simpler quantities. For example, our eyes are basically a pair of pretty crappy photon detectors and thus when we look at a water sample we are simply carrying out a very noisy and inefficient POVM. Now here is the main point: when you only have access to fewer observables then you can formulate a \emph{simpler hypothesis} which can still explain all the observational data you can obtain. This simpler hypothesis is an \emph{effective theory} for the system. Simpler here can mean many things, but in the context of this paper it is via a field theory\footnote{Why are fields simple? The answer is calculus: it is often easier to calculate integrals than sums.}.

How can we model the large-scale degrees of freedom that we humans with our limited resources can access? One very simplified way is by developing a \emph{zooming out} operation. Since zooming out corresponds to \emph{ignoring information}, this operation should be representable in quantum mechanics as an irreversible CP map $\mathcal{E}$. The reason that it has to be irreversible is that it must prevent us from measuring degrees of freedom that we would otherwise be able to measure: after all, if we could measure all the observables after zooming out that we could measure before then in what sense can we be have said to have zoomed out? In the context of lattice systems there is a very convenient way to implement the zoom-out operation, namely, via Kadanoff blocking. This is the CP map whereby a block of spins is mapped to single spin via the partial trace channel, and then the lattice is rescaled.

Suppose we have some tremendously complicated microscopic system of degrees of freedom at some fundamental length scale $\Lambda$ in some state $\rho_\Lambda$. However, we can only perform limited measurements at our terrestrial length scale $\sigma$ modelled by effects of the form $\mathcal{E}_{\sigma}(E)$, where $E \in \mathcal{A}_{\sigma}$ is an effect in the space of \emph{our} observables. Since we can only measure a handful of all the possible observables $\mathcal{A}_\Lambda$ on the microscopic theory, we are satisfied with the explanation provided by any \emph{effective state} $\rho_{\text{eff}}$ which looks indistinguishable from $\rho_\Lambda$ according to any measurement $\mathcal{E}_{\sigma}(E)$, i.e.\ any state obeying
\begin{equation}
	\tr(\mathcal{E}_{\sigma}(E) (\rho_\Lambda - \rho_{\text{eff}})) \approx 0, \quad \text{for all } E\in \mathcal{A}_\sigma.
\end{equation}
The fewer the observables we can measure, the simpler our hypothesis for $\rho_{\text{eff}}$ can be. In the case of fields, we are only able to measure a handful of observables $E(x)$ indexed by some continuous label $x$; we'll explain this a bit more concretely in the following sections.

One aspect of this discussion may be puzzling for readers familiar with quantum field theories: why are we insisting on saying a change of scale is a lossy operation when, e.g., in CFTs a scale change is a \emph{reversible unitary operation}? The answer is that, in terms of a \emph{microscopic theory} with a cutoff, zooming out \emph{must} be a lossy operation as we can push degrees of freedom past the cutoff. However, in terms of an effective theory, a scale change can be unitary because there is an effective decoupling of the large-scale  and the small-scale degrees of freedom and the action of a finite scale change doesn't, \emph{in the large cutoff limit}, couple the different sets of degrees of freedom. 

A quantum information theorist may find the analogy with noiseless subsystems helpful: if you like, effective theories are analogous to (approximate) decoherence-free subspaces/subsystem codes, where the errors in this case are induced by scale changes. This is a quantitative way to understand what is meant by IR/UV decoupling. If zooming out is a CP map $\mathcal{E}$ then what is ``zooming in'', or \emph{UV completion}? The answer is that there is no unique answer: any CP map $\mathcal{D}$ such that $\mathcal{D}\circ \mathcal{E} \equiv \mathcal{I}$ can be given the interpretation as a zooming in map. That is, first adding details (zooming in) and then removing them (zooming out) should have no effect (recall that we write the channels in the Heisenberg picture, so the order is inverted). Exploiting once more the analogy with noiseless subsystems you can think of zooming in as an error recovery operation $\mathcal{D}$ on the large-scale degrees of freedom. We will return to this point later.

\section{The Wilsonian formulation of effective quantum field theory}\label{sec:wilson}
\red{[This is confusing because you are really talking about lagrangian, but using symbols already defined to mean observables etc..]}

Here we review, broadly following the expositions of \cite{wilson_renormalization_1975} and \cite{moore_lecture_2012}, the Wilsonian view of quantum field theory as an effective field theory. It is \emph{not at all} necessary to understand the discussion here at anything other than a metaphoric level as we are going to revisit the ideas of this section many times in the sequel to make the intuitive discussions here more concrete. Just read through the description and try and absorb the general flavour. 

Traditionally the Wilsonian formulation is discussed in terms of the path integral representation. We choose to avoid all the details of this representation: for the purposes of the overview here it is enough to regard a path integral as a \emph{box} which is parametrised by a \emph{lagrangian} $\mathcal{L}$ which is itself parametrised by some numbers, called \emph{coupling constants}, which can produce vacuum expectation values of certain ``observables'' we want to call quantum field operators:
\begin{equation}
	\langle \Omega|\mathcal{T}\{\widehat{\phi}(x_1)\widehat{\phi}(x_2)\cdots \widehat{\phi}(x_n)\}|\Omega\rangle
\end{equation}

In the Wilsonian formulation we begin with the space of observables/effects $\mathcal{A}_{\text{reg}}$ of \emph{regulated} or \emph{cutoff} quantum field theories\footnote{Remember: we always specify our theories in terms of observables.}. What are these? Well, there are an infinite number of ways to define them, but one you can keep in mind is by simply putting a theory on a lattice. It is important, at this stage, to emphasise that the regulated theories are the only ones which are expected to make mathematical sense. You can think of $\mathcal{A}_{\text{reg}}$ as the (direct sum of the) space of observables for all possible theories of bosons and fermions hopping on lattices with some \emph{nonzero} lattice spacing $a = 1/\Lambda$. (This way of defining a cutoff QFT is certainly not the most elegant, but it does enjoy considerable advantages for evaluation on a computer.) Thus $\mathcal{A}_{\text{reg}}$ can be thought of as the space of all lattice theories with nonzero lattice spacings: for each $\Lambda$ there is a subspace $\mathcal{A}_\Lambda$ corresponding to the observables/effects of lattice theories with a cutoff given by $\Lambda$, and these are all identified with their image in $\mathcal{A}_{\text{reg}}$ via some \emph{embedding} map $f_\Lambda:\mathcal{A}_\Lambda\rightarrow \mathcal{A}_{\red{\rm reg}}$. 

Once you have cut off a quantum field theory most, if not all, of the nasty divergences you've heard about disappear, and we only have to cope with more pedestrian divergences familiar to condensed matter physicists (e.g., the ``orthogonality catastrophe'' and ``infrared divergences''). 

One might be tempted to think that $\mathcal{A}_{\text{reg}}$ is already the space of observables of quantum field theories. However, this is really not the case: any observable/effect in the space $\mathcal{A}_{\text{reg}}$ corresponds, by construction, to an observable/effect for a lattice with a \emph{finite} cutoff $\Lambda$. This cutoff can be arbitrarily large but it must always be finite and thus there is always an underlying lattice structure (be it in momentum or position space or otherwise). A good analogy to keep in mind here is that between the rational numbers $\mathbb{Q}$ and the real numbers $\mathbb{R}$: any element of $\mathbb{Q}$ is expressible as $a/b$ with $a<\infty$ and $b < \infty$. However, something like $\sqrt{2}$ would need to be expressed as a rational number with infinitely large numerator and denominator, i.e., there are many numbers `missing' from $\mathbb{Q}$. 

Hence we now imagine that $\mathcal{A}_{\text{reg}}$ lives inside some even larger space $\mathcal{A}$ of ``all'' observables/effects of quantum field theories (whatever that might mean), with or without regulator. This is rather vague, but we argue below that we can ignore almost all the theories in $\mathcal{A}\setminus\mathcal{A}_{\text{reg}}$, as only a small fraction are \emph{physically relevant}.

Let's now construct a proper quantum field theory, i.e., a theory without cutoff. To do this suppose that for a particular given theory $(\mathcal{A}_\Lambda, \mathcal{E}_{t,\Lambda}, \omega_\Lambda)$ with observables $\mathcal{A}_\Lambda \subset \mathcal{A}_{\text{reg}}$ and cutoff $\Lambda$ we can always find a \emph{physically equivalent} theory $(\mathcal{A}_{\Lambda'}, \mathcal{E}_{t,\Lambda'}, \omega_{\Lambda'})$ with $\mathcal{A}_{\Lambda'} \subset \mathcal{A}_{\text{reg}}$ having a larger cutoff $\Lambda' > \Lambda$. If we can always do this then there is nothing stopping us sending the cutoff $\Lambda'\rightarrow \infty$ and calling the result a quantum field theory proper.  

What does it mean for a theory to have a larger cutoff than another theory? One clean operational interpretation is that all the \emph{effects} of our original theory can be found in the space of effects for the new theory with a larger cutoff. Thus, corresponding to the operation of changing cutoff from $\Lambda$ to $\Lambda' > \Lambda$, there must be a map
\begin{equation}
	\mathcal{F}_{\Lambda,\Lambda'}: \mathcal{A}_\Lambda \rightarrow \mathcal{A}_{\Lambda'}
\end{equation}
which identifies the effects of the lower-cutoff space with corresponding \emph{physically identical} effects in the higher-cutoff space. 
How do we determine this map? The standard answer is that the \emph{low-order correlation functions of large-scale low-energy observables} need to be preserved under the cutoff changing operation $\mathcal{F}_{\Lambda,\Lambda'}$. In other words: if we make a prediction for low-energy large-scale observables using a theory with cutoff $\Lambda$ then a \emph{physically equivalent} theory $\mathcal{A}_{\Lambda'}$ must give the same predictions for the original low-energy large scale observables. This map is not trivial to determine; this is where we need to do some physics! \red{[shouldn't one refer to $\mathcal E$ here as defining "low-energy" or "large-scale" since it is mentioned before?, or are we avoiding this because this is Wilson's view? But then already introducing $\mathcal E$ before this paragraph might be confusing?]}

Suppose we assume further that the dependence of $\mathcal{F}_{\Lambda,\Lambda'}$ is continuous \red{[You mean $\Lambda$ continuous..]}, then we generate a \emph{flow} on $\mathcal{A}_{\text{reg}}$ (and hence on $\mathcal{A}$) via the map  \red{[What could $f^{-1}$ be? ]}
\begin{equation}
	f_{\Lambda'}\circ \mathcal{F}_{\Lambda,\Lambda'}\circ f_\Lambda^{-1}   
\end{equation}   
according to the diagram
\begin{equation}
\xymatrix{
\mathcal{A}_{\Lambda} \ar[rr]^{\mathcal{F}_{\Lambda,\Lambda'}}
\ar[dr]_{f_\Lambda}\hole
&& \mathcal{A}_{\Lambda'} \ar[dl]^{f_{\Lambda'}}\\
& \mathcal{A}_{\text{reg}} }
\end{equation}
\red{[What about states? I don't understand this...]}
It is usually assumed  that that this flow on the infinite-dimensional space $\mathcal{A}_{\text{reg}}$ is generated by a \emph{vector field}, called the \emph{beta function}. A very special role is played by the \emph{fixed points} of this flow, as they correspond to genuine cutoff-free quantum field theories, i.e., theories of continuously many degrees of freedom. But does $\mathcal{A}_{\text{reg}}$ contain any such fixed points? This is an important question which leads us closer to a resonable definition of $\mathcal{A}$ as the original space $\mathcal{A}_{\text{reg}}$ with missing points adjoined. Again the analogy with $\mathbb{Q}$ is helpful here: fixed points of well-defined maps on $\mathbb{Q}$ can easily fail to be in $\mathbb{Q}$, for example, consider $f(x) = x^2-1$: the fixed points of this map are $x_{\pm} = \frac{1\pm\sqrt{5}}{2}$. Thus we can tentatively think of $\mathcal{A}$ as the space of regulated theories with possibly missing fixed points of $\mathcal{F}_{\Lambda,\Lambda'}$ adjoined. It turns out that this picture is pretty close to the actual definition. Conformal field theories, being scale invariant, are then precisely fixed points.

It is standard to parametrise QFTs by \emph{local lagrangians}, which basically sort of amounts to a choice of a coordinate system for our mythical $\mathcal{A}$. Doing things this way tends to incentivise the  conflation of both states and effects into one object via the \emph{path integral}. The space $\mathcal{M}$ of lagrangians is an infinite-dimensional linear manifold with a coordinate for each local term you can add, e.g., 
\begin{equation}
	\mathcal{L} = c_0 + c_1\phi + c_2\phi^2 + c_3\phi^2 + \cdots + d_0 \phi \square \phi + d_1 \partial_\mu \phi \partial^\mu \phi +\cdots+ \text{etc.}
\end{equation}
Here a QFT is parametrised by the infinite list $(c_0, c_1, c_2, \ldots, d_0, d_1, \ldots, \text{etc.}) \in \mathbb{R}^\infty$. Lagrangians are, in combination with the path integral, a wonderfully compact way specify QFTs in a way that makes locality, causality, and symmetries such as Lorentz invariance manifest. However, they have the not inconsiderable downside that it is often very hard to compute correlation functions except perturbatively around special points.  

When we do things this way the maps $f_\Lambda$ and $\mathcal{F}_{\Lambda,\Lambda'}$ become \emph{diffeomorphisms} and the requirement that, after increasing the cutoff from $\Lambda$ to $\Lambda'$, the $n$-point correlation functions of large-scale low-energy observables remain invariant generates a deeply nontrivial \emph{renormalisation group} (RG) flow on the infinite dimensional manifold $\mathcal{M}$. 

The point of view taken in this paper is to describe how to apply the Wilsonian view to different, indeed arbitrary, ways of parametrising QFTs. A key step is to first separating out states and observables into separate categories. As a crucial example, we'll show how to exploit \emph{tensor network states} to parametrise QFTs by implementing the continuum limit in the Wilsonian view directly on quantum states rather than lagrangians.


\section{Effective quantum field states and the Wilsonian formulation}\label{sec:effectiveqftstates}
\red{[Nearly same title as previous section...]}

The core objective of these notes is to come up with a definition of a \emph{quantum field state} which is hopefully applicable across a broad range of situations from systems with a lattice cutoff to systems with a momentum cutoff, and beyond. However, the Wilsonian formulation described in the previous section, applying as it does to a hybrid of the observables and states, doesn't directly suggest a good definition; we'll need to employ a little imagination to extract a general formulation which looks a little friendlier for quantum information theorists. 

Casting an eye over the discussion in the previous section we isolate three core ingredients:
\begin{enumerate}
	\item A space of observables $\mathcal{A}_{\text{reg}}$ for \emph{regulated} theories which are mathematically well behaved. The space $\mathcal{A}_{\text{reg}}$ should be naturally parametrised by one or more a \emph{cutoffs}\footnote{It turns out that when you have more general cutoffs, e.g., by arbitrary nonregular spatial discretisations, then the additional structure you need is a \emph{partial order} on the space of cutoffs; this is usually canonical and we only discuss this problem in the context of two examples.} $\Lambda$, so that we can identify in $\mathcal{A}_{\text{reg}}$ the subspace $\mathcal{A}_{\Lambda}$ of theories with cutoff $\Lambda$. There is a great deal of arbitrariness here and we only pursue the details for two examples, namely, the momentum-space and real-space cutoffs. 
	\item A way to \emph{compare} the predictions of two theories with \emph{different} cutoffs -- an \emph{information metric}. We do this by agreeing on an operationally motivated distance measure on the \emph{state spaces} $\mathcal{S}_\Lambda$ of the $\mathcal{A}_\Lambda$s, and then extending this to the state space $\mathcal{S}_{\text{reg}}$ of \emph{all} regulated states on $\mathcal{A}_{\text{reg}}$.
	\item A definition for ``large-scale'' observables. This is done by specifying a \emph{completely positive map} $\mathcal{E}_\sigma : \mathcal{A}_{\text{reg}} \rightarrow \mathcal{A}_{\text{reg}}$, parametrised by one or more \emph{resolution} or \emph{scale parameters} $\sigma$, whose image is the convex set of all those effects measurable by large-scale observers (i.e., those measurement that we mere mortals can perform). It is only with respect to these observables that we actually compare two quantum field states.
\end{enumerate}  
As we argue below, once we've specified this ``minimal data'' we can exploit the Wilsonian view to define what is meant by a quantum field state.    

To concretely illustrate the components of the Wilsonian formulation we'll specifically refer to two important examples. The first example is a standard choice in QFT, namely that of the (hard or smooth) momentum cutoff. We briefly sketch the data required for the Wilsonian formulation in this case and connect it with the traditional description of perturbative interacting QFT by specifying a ``zooming-out'' CP map. The second example we consider, namely, the real-space cutoff requires a little more care to put it into a form appropriate for the Wilsonian formulation: here we encounter additional problems because we need to compare lattices with different lattice spacing. We show how Kadanoff blocking supplies us with a solution, and further how to use introduce a ``zooming-out'' CP map describing the large-scale observables. 

\subsection{The momentum cutoff}
The class of examples is formulated in terms of

Key points to stress: we automatically have a way to compare two states with different cutoff.

\subsection{The real-space cutoff}
The real-space cutoff is implemented by putting the system on a lattice with (variable) lattice spacing $a$. In discussing the real-space cutoff case we encounter an additional problem which we did not (directly) have to engage with in the momentum cutoff case, namely, how do we compare two systems with different lattice spacing? 

We begin by building the space of observables for a one-dimensional system with a \emph{fixed} real-space cutoff, i.e., a lattice $L_a$ with spacing $a$: this is a regular partition of the real line $\mathbb{R}$ by a collection of lattice cells of the form $I_j \equiv [ja, (j+1)a)$, i.e., $L_a \equiv \{I_j\}_{j\in \mathbb{Z}}$. For concreteness we focus on the example a system where we associate a quantum spin-$1/2$ degree of freedom (i.e., a qubit) with each lattice \emph{cell}\footnote{We associate degrees of freedom with cells rather than vertices as we (usually) regard them as representing the averaged value of some physical quantity, e.g., angular momentum, over the cell.}, or \emph{link}, $I_j$. The hilbert space for such a system would naively be the infinite tensor product of $\mathbb{C}^2$, one for each lattice cell. However, we avoid the discussion of how to make sense of this for the moment and instead describe the arguably more natural space of observables for this system. This space is built as follows: for any finite subset $\Lambda \subset L_a$ of lattice cells let $\mathcal{A}(\Lambda)$ be the tensor product of $M_2(\mathbb{C})$ over each $I_j\in \Lambda$. For $\Lambda_1\subset \Lambda_2$ we identify $\mathcal{A}(\Lambda_1)$ in a natural way with $\mathcal{A}(\Lambda_1)\otimes \mathbb{I}_{\Lambda_2\setminus \Lambda_1} \subset \mathcal{A}(\Lambda_2)$. For infinite $\Lambda \subset L_a$ denote by $\mathcal{A}(\Lambda)$ the $C^*$-closure of the increasing family of finite-dimensional algebras $\mathcal{A}(\Lambda_f)$ with $\Lambda_f \subset \Lambda$. What this means in words is that $\mathcal{A}(\Lambda)$ contains all observables which act on at most a finite number of spins as well as observables which are \emph{well approximated} by sequences of observables acting on at most a finite number of spins. The \emph{quasi-local algebra} is then $\mathcal{A}(L_a)$, and this is the space of observables we associate with our regulated system. 

To get a feel for what kinds of observables live in $\mathcal{A}(L_a)$ we consider a couple of examples. The simplest is a single-site operator, e.g., $\sigma^z_j$ (we adopt the simpler subscript notation $A_j \equiv A_{I_j}$ for an operator acting nontrivially only on lattice cell $I_j$). An example of an observable well-approximated by a sequence of finite-support operators is $\sum_{j\ge 0} e^{-j}\sigma^z_0 \sigma_1^z  \cdots \sigma_{j-1}^z\sigma_j^z$. An important class of observables that \emph{do not} live in $\mathcal{A}(L_a)$ are the ``bulk field''-type observables, e.g., $M_z \equiv \sum_{j\in\mathbb{Z}} \sigma^z_j$. Another type of observable that doesn't live in $\mathcal{A}(L_a)$ is given by the finite-rank projections $P$. Also, spectral projections for bulk observables like $M_z$ are outside of $\mathcal{A}(L_a)$. This ``deficit'' of the observable set $\mathcal{A}(L_a)$ can be corrected by passing to a von Neumann algebra, however this requires the introduction of a reference state, a step we don't yet wish to take. 

The space $\mathcal{A}(L_a)$ is specifically tied to a lattice with a \emph{fixed} spacing $a$. However, the space $\mathcal{A}_{\text{reg}}$ of regulated observables should contain observables with arbitrary (yet always nonzero) real-space cutoff $a$. The way we accommodate this possibility is to build $\mathcal{A}_{\text{reg}}$ from the \emph{direct sum} of $\mathcal{A}(L_a)$ over a sequence of allowed values of the lattice spacing $a$. It is possible to allow any nonnegative value for $a$, but this is a little more awkward in practice. As we'll see, allowing $a$ to be an arbitrary simple dyadic rational of the form $2^{-j}$ will already suffice. The way to capture all these possible observables is then via the object 
\begin{equation*}
	\mathcal{A}_{\text{pre}} \equiv \bigoplus_{j \in \mathbb{Z}^+} \mathcal{A}(L_{2^{-j}}).
\end{equation*}
This is an economical way of allowing observables of lattices of arbitrarily small lattice spacing\footnote{The astute reader will notice that $\mathcal{A}_{\text{pre}}$ doesn't contain the identity. We'll mostly ignore this subtlety because an approximate identity suffices to yield a reasonable operational interpretation.}. The kind of physical situation modelled by the observable set $\mathcal{A}_{\text{pre}}$ is that of a system with a classical dial controlling the lattice spacing (this can be implemented in the laboratory by putting sample in a liquid and increasing the pressure). A typical positive observable living in $\mathcal{A}_{\text{pre}}$ has the form of a finite convex combination $\sum_{l=1}^n M_{a_l}$ of observables $M_{a_l}$ for lattices with possibly different spacings $a_l$; such observables correspond to the experiment where a collection of coins are first flipped and, conditioned on the outcome, the observable $M_{a_l}$ is subsequently measured. 

It turns out that the observable set $\mathcal{A}_{\text{pre}}$ doesn't quite correspond to situation we wish to model -- it is a little too large. This is because there is no notion of whether an observable corresponds to the same physical quantity, only measured on a lattice with a different lattice spacing. The picture to have in mind here is of a neutron scattering experiment where the same impinging beam scatters from the sample, regardless of the lattice spacing. To express this additional structure we introduce an equivalence relation on $\mathcal{A}_{\text{pre}}$ by introducing the subspace $N \subset \mathcal{A}_{\text{pre}}$ generated by all the differences $M_{a}-M_{a'}$, where $M_{a}$ and $M_{a'}$ are meant to correspond to the same experiment, only on different lattice spacings $a$ and $a'$. Using $N$ we can finally define $\mathcal{A}_{\text{reg}}$:
\begin{equation}
	\mathcal{A}_{\text{reg}} \equiv \mathcal{A}_{\text{pre}}/N.
\end{equation}
The equivalence relation on observables, and subsequently, the definition of $N$, is determined by \emph{physics}, and no amount of abstract nonsense will assist us in going further. 

In order to prevent this discussion from becoming too ethereal we now consider a particular concrete example in some detail. The physical picture we have in mind for this example is that of a quantum magnet with ground state $|\Omega\rangle \equiv \bigotimes_{j\in\mathbb{Z}} |0\rangle$. The magnet is assumed to have some magnons, represented as $|1\rangle$ states at certain locations, propagating around. For a given lattice spacing the state $|1\rangle_{I_j}$ represents a quantum magnon in somewhere in $I_j$, i.e., completely delocalised across the lattice cell $I_j$. If we subdivide the lattice cell into two contiguous equal-sized pieces $I_j \equiv I_{2j}'\cup I_{2j+1}'$ then it ought to be the case that $|1\rangle_{I_j}$ is an equal superposition of the magnon being on the left and right sides:
\begin{equation}
	|1\rangle_{I_j} \equiv \frac{1}{\sqrt{2}} \left(|1\rangle_{I_{2j}'}|0\rangle_{I_{2j+1}'}+|0\rangle_{I_{2j}'}|1\rangle_{I_{2j+1}'}\right).
\end{equation}
So far this notion of equivalence has been described in terms of states rather than observables. To implement our equivalence relation in terms of observables we introduce the \emph{interpolation} unitary $U:\mathbb{C}^2\otimes \mathbb{C}^2\rightarrow \mathbb{C}^2\otimes \mathbb{C}^2$:
\begin{equation}
	U \equiv \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} & 0 \\ 0 & \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} & 0 \\ 0 & 0 & 0 & 1\end{pmatrix}.
\end{equation}
Using $U$ we build the CP map (in the heisenberg picture):
\begin{equation}
	\mathcal{E}(A) \equiv U^\dag (A\otimes \mathbb{I}) U.
\end{equation}
This map identifies the observables for a given interval $I_j$ with the physically identical observables for two equal sized contiguous intervals $I_{2j}$ and $I_{2j+1}$. The corresponding CP map in the Schr\"odinger picture is given by
\begin{equation}
	\mathcal{E}^{*}(\rho) \equiv \tr_2( U \rho U^\dag),
\end{equation}
and has the property that it maps the state $|00\rangle$ to $|0\rangle$ and $\frac{1}{\sqrt{2}} \left(|10\rangle+|01\rangle\right)$ to $|1\rangle$. 

\red{[The symbol $\mathcal E$ was used for the coarse-graining before...]}
Using the map $\mathcal{E}$ we build the map 
\begin{equation}
	\mathcal{F}_{j,j+1} \equiv \bigotimes_{j\in 2\mathbb{Z}} \mathcal{E},
\end{equation}
which naturally acts from $\mathcal{A}_{2^{-j}}$ to $\mathcal{A}_{2^{-j+1}}$. The schr\"odinger picture version $\mathcal{F}_j^{*}$ of $\mathcal{F}_{j}$ is nothing but a \emph{Kadanoff blocking} of the lattice where we block spins together in pairs, apply some blockwise unitary $U$, and then trace out every second spin. We then define, for all $j, k \in \mathbb{Z}^+$ with $j < k$, the map
\begin{equation}
	\mathcal{F}_{j,k}\equiv \mathcal{F}_{k-1,k}\circ \mathcal{F}_{k-2,k-1} \circ \cdots \circ \mathcal{F}_{j,j+1}
\end{equation}
representing a sequence of $k-j$ Kadanoff blocking operations.
Using $\mathcal{F}$ we finally introduce an equivalence relation $\sim$ by identifying $M \in \mathcal{A}_{2^{-j}}$ with $\mathcal{F}_{j,k}(M) \in \mathcal{A}_{2^{-k}}$. Thus we build the subspace $N\subset \mathcal{A}_{\text{pre}}$ generated by all differences $M_j - \mathcal{F}_{j,k}(M_j)$, for all $j<k$ and all $M_j\in \mathcal{A}_{2^{-j}}$, and hence define $\mathcal{A}_{\text{reg}} \equiv \mathcal{A}_{\text{pre}}/N$.
Thus we've arrived at our first ingredient required by the Wilsonian formulation, namely, a space $\mathcal{A}_{\text{reg}}$ of observables containing effects corresponds to experiments with respect to any allowed lattice with a finite yet non-zero spacing. 

We can now describe the space of $\mathcal{S}_{\text{reg}} \equiv \mathcal{S}(\mathcal{A}_{\text{reg}})$ of \emph{regulated field states}. The way to understand a state $\rho$ in this space is as an infinite direct sum $\rho_{\text{reg}} \equiv \bigoplus_{j\in \mathbb{Z}^{+}} \rho_{j}$ of states $\rho_{j} \in \mathcal{S}(\mathcal{A}_{2^{-j}})$, one for each lattice $L_{2^{-j}}$, such that for all $j<k$ the states $\rho_j$ and $\rho_k$ \emph{exactly} satisfy $\rho_j \equiv \mathcal{F}^{*}(\rho_k)$. In words: a regulated field state $\rho_{\text{reg}}$ is a sequence of states which are generated by Kadanoff blockings of each other. A simple example here is $|\Omega\rangle\langle \Omega| \equiv (\rho_j)_{j\in \mathbb{Z}^+}$, where $\rho_j \equiv |\Omega_j\rangle\langle \Omega_j|$ with $|\Omega_j\rangle \equiv \bigotimes_{l\in \mathbb{Z}} |0\rangle$. However there are more complicated states inside $\mathcal{S}_{\text{reg}}$. For example, let $\chi_{[a,b)}:\mathbb{R}\rightarrow\mathbb{R}$ be the simple function
\begin{equation}
	\chi_{[a,b)}(x) = \begin{cases} 1& \quad a\le x < b, \\ 0& \quad \text{otherwise,}\end{cases}
\end{equation}
where $a,b\in\mathbb{R}$. Build the state
\begin{equation}
	|\chi_{[0,1)}\rangle_j \equiv 2^{-\frac{j}{2}}\sum_{k\in \mathbb{Z}} \chi_{[0,1)}(k2^{-j}) |k\rangle_j
\end{equation}
where 
\begin{equation}
	|k\rangle_j = \left(\bigotimes_{\substack{l\in\mathbb{Z} \\ l < k}} |0\rangle \right)\otimes |1\rangle \otimes\left(\bigotimes_{\substack{l\in\mathbb{Z} \\ l > k}} |0\rangle \right).
\end{equation}
One can verify that $|\chi_{[0,1)}\rangle_j\langle \chi_{[0,1)}| = \mathcal{F}_{j,k}^{*}(|\chi_{[0,1)}\rangle_k\langle \chi_{[0,1)}|)$ and thus we obtain a well-defined state $|\chi_{[0,1)}\rangle$ on $\mathcal{A}_{\text{reg}}$.

A plethora of interesting states may be built by exploiting the following \emph{right inverse} CP map $\mathcal{G}^{(*)}$ of $\mathcal{F}^{(*)}$, described in the Schr{\"o}dinger picture by
\begin{equation}
	\mathcal{G}_{j+1,j}^{(*)} \equiv \bigotimes_{j\in 2\mathbb{Z}} \mathcal{E}'.
\end{equation}
where
\begin{equation}
	\mathcal{E}'(\rho) \equiv U(\rho\otimes |0\rangle\langle 0|) U^\dag.
\end{equation}
This is only one of an infinite number of possible right inverses of  $\mathcal{F}^{(*)}$; replacing $|0\rangle$ by any other single qubit state in the definition of $\mathcal{E}'$ produces another right inverse.
One can confirm that
\begin{equation}
	\mathcal{F}_{j,j+1}^{(*)}\circ \mathcal{G}_{j+1,j}^{(*)} \equiv \mathcal{I}_j.
\end{equation}
We now see that the example presented above, namely $|\chi_{[0,1)}\rangle$, can be constructed by applying $\mathcal{G}_{j+1,j}^{(*)}$ repeatedly to the initial state $|0\rangle_0 \equiv |\chi_{[0,1)}\rangle_0$. Indeed, any state $\rho_0$ on $\mathcal{A}_{2^{-0}}$ can be exploited in the same way to produce a state on $\mathcal{A}_{\text{reg}}$.



The next vital ingredient for the Wilsonian formulation is the selection of an operationally motivated distance measure on $\mathcal{A}_{\text{reg}}$. We again employ the Bures metric on $\mathcal{S}(\mathcal{A}_{2^{-j}})$:
\begin{equation}
	D^2_j(\rho_1,\rho_2) \equiv 2\left(1-\tr\left(\sqrt{\sqrt{\rho_1}\rho_2\sqrt{\rho_1}}\right)\right).
\end{equation}
(Here we are assuming the states are representable as trace-class operators; we intend to be cavalier about such things throughout these notes. For the reader concerned about the lack of rigour at this point we simply mention that a sensible way to deal with this quantity is to go to the GNS representation afforded by the state $\rho_1$.)

It is a nontrivial question how this metric extends from $\mathcal{S}(\mathcal{A}_{2^{-j}})$ to $\mathcal{S}_{\text{reg}}$ in a natural way. We deal with this by defining, for any pair $\rho_1$ and $\rho_2$ of states in $\mathcal{S}_{\text{reg}}$ the metric
\begin{equation}
	D^2(\rho_1,\rho_2) \equiv \lim_{j\rightarrow\infty}  D^2_j(\rho_{1,j},\rho_{2,j}).
\end{equation}
The existence of this limit is guaranteed by the fact that $D^2_j(\rho_{1,j},\rho_{2,j})$ is a nonnegative bounded monotone increasing function of $j$, thanks to the fact that the Bures metric is \emph{monotone} and that $\rho_{1,j}$ (respectively, $\rho_{2,j}$) is the image of the CP map $\mathcal{F}_{j,k}^{*}$ applied to $\rho_{1,k}$ (respectively, $\rho_{2,k}$).


At this stage, before introducing our final ingredient, we need to produce a representation $\pi$ of the regulated observables $\mathcal{A}_{\text{reg}}$. 

The final ingredient we need for a Wilsonian formulation is the identification of a subset $\mathcal{A}_\sigma$ of observables corresponding to an experiment at some large terrestrial scale $\sigma$. We achieve this by building a ``blurring'' CP map $\mathcal{D}_{\sigma}:\mathcal{A}_{\text{reg}}\rightarrow \mathcal{A}_{\text{reg}}$ and define 
\begin{equation}
	\mathcal{A}_\sigma \equiv \mathcal{D}_{\sigma}(\mathcal{A}_{\text{reg}}).
\end{equation}
There is a deal of arbitrariness here in how we define blurring maps; there is no abstract recipe we can appeal to. Instead we again need to do some physics. The following map may be argued to provide a reasonable model for observables accessible at scale $\sigma > 0$: we begin by introducing the Lindblad operator $\mathcal{L}^{(j)}:\mathcal{A}_{2^{-j}} \rightarrow \mathcal{A}_{2^{-j}}$, where
\begin{equation}
	\mathcal{L}^{(j)}(\cdot) = 2\sum_{k\in \mathbb{Z}} \left(\textsc{swap}_{k,k+1}(\cdot)\textsc{swap}_{k,k+1} - \mathcal{I}(\cdot)\right),
\end{equation}
and $\mathcal{I}$ is the identity superoperator. This Lindblad generator may then be exploited to define the CP map
\begin{equation}
	\mathcal{D}_\sigma^{(j)} \equiv e^{(\sigma 2^{j})^2\mathcal{L}^{(j)}}.
\end{equation} 
We set aside, for the moment, the question of the continuity of this operator: a relatively simple argument shows that it acts continuously on operators with finite support -- it is at least strongly continuous with respect to the strong-operator topology generated by the GNS representation afforded by the product state $|\Omega\rangle$). Physically speaking the CP map $\mathcal{D}_{\sigma}$ subjects operators to a diffusion process for a period of ``time'' $\tau = (\sigma 2^{j})^2$: for large times $\tau$ any local operator $A_k$ will evolve to an operator of the form $e^{\tau\mathcal{L}^{(j)}}(A_k) \approx \frac{1}{\sqrt{8\pi \tau}}\sum_l e^{-\frac{(l-k)^2}{8\tau}} A_l$.

Because this is a diffusion process we know that a typical operator will have wandered approximately $\sqrt{\tau} = \sigma 2^j$ sites from its initial position. Since the lattice spacing is $2^{-j}$ we see that an operator initially localised at some position will have wandered approximately a physical distance $\sigma$ from its initial position. The diffusion map $\mathcal{D}_\sigma^{(j)}$ can now be used to build a blurring map on $\mathcal{A}_{\text{reg}}$ in the following fashion. Firstly, note that the action of $\mathcal{D}_\sigma^{(j)}$ can be extended in a well-defined way to apply to all of $\mathcal{A}_{\text{reg}}$ exploiting the channels $\mathcal{F}$ and $\mathcal{G}$:
\begin{equation}
	\mathcal{D}_\sigma^{(j)}(A_k) = \begin{cases} \mathcal{D}_\sigma^{(j)}\circ\mathcal{F}_{k,j}(A_k), \quad k < j \\
	\mathcal{F}_{k,j}\circ\mathcal{D}_\sigma^{(j)}\circ\mathcal{G}_{k,j}(A_k), \quad k > j. \end{cases}
\end{equation}
Using the channel $\mathcal{D}_\sigma^{(j)}$ we arrive at our final definition
\begin{equation}
	\mathcal{D}_\sigma \equiv \lim_{j\rightarrow \infty} \mathcal{D}_\sigma^{(j)}.
\end{equation}
Here the limit must be taken with respect to a topology on $\mathcal{A}_{\text{reg}}$; we expect that the limit exists in the strong-operator topology, but it is plausible that it also exists for the norm topology (although, to be honest, we aren't that hopeful...) 

The limiting channel $\mathcal{D}_\sigma$ may be described in words as follows: suppose we have an observable $A_j$ on a lattice with spacing $2^{-j}$. First embed this operator into an equivalent fine-grained observable on the lattice with finer spacing $2^{-k}$ using the channel $\mathcal{F}_{j,k}$. Then subject this fine-grained observable to blurring according to $\mathcal{D}_\sigma^{(k)}$. As $k$ is taken larger and larger the result of this operation will be a sequence $\mathcal{D}_\sigma^{(k)}(A_j)$ of observables in $\mathcal{A}_{\text{reg}}$ on finer and finer lattices. These observables will be better and better approximated by a gaussian weighted mixture of translates of the initial operator. The actual action of this channel is depicted in the following figure. 

Finally, we define the large-scale observables at scale $\sigma$ to be the image of $\mathcal{A}_{\text{reg}}$ under $\mathcal{D}_\sigma$:
\begin{equation}
	\mathcal{A}_\sigma \equiv \mathcal{D}_\sigma(\mathcal{A}_{\text{reg}}).
\end{equation}

For the reader dissatisfied with the density of unproven assertions in previous the construction of the large-scale observables we supply here an alternative, presumably equivalent, construction.

\section{Quantum field states via completion}\label{sec:qftcompletion}
Let's tell a story about how physicists on a world far far away might have invented the real numbers $\mathbb{R}$.  The scientists of this world wanted to measure distances using rulers with tick marks spaced at regular intervals. On this world it was agreed that all rulers had to have their ticks spaced by fractions of some standard tick length $a_0$ (the length of the emperor's foot). Thus the tick spacing $\epsilon a_0$ of a ruler was required to be a positive rational ratio $\epsilon \in \mathbb{Q}^+$ of the standard tick length $a_0$. Owing to its canonical nature $a_0$ was set to $1$ by convention. To the scientists of this world all lengths were rational numbers. 

Now a scientist in possession of a ruler of accuracy $\epsilon$ would deem two lengths $x$ and $y$ differing by $\epsilon$ to be \emph{indistinguishable} (they rounded everything down on this world), i.e., two points $x$ and $y$ were \emph{$\epsilon$ equivalent} if
\begin{equation}
	x\sim_\epsilon y \Leftrightarrow |x-y| < \epsilon. 
\end{equation} 
For the longest time it was assumed that all lengths had rational values, after all, you could always build a better ruler to measure a length more accurately. 

However, one day it came to pass that a radical, clever, and sadly, unfortunate, scientist on this world made a shocking realisation: there could be a length $x^\star = \sqrt{2}$ which was \emph{not} exactly a rational number! Of course, this poor scientist was summarily executed (there is nothing worse than a smart ass). However, the argument gnawed at the minds of the conservative establishment for decades, and much hot air expended in coming to terms with it. Eventually, the inhabitants of this world came to the following construction. Obviously noone on the planet could measure the length $x_{\epsilon} = n\epsilon$ to be anything other than a multiple $n$ of the ticklength $\epsilon$ found from $n = \lfloor x^\star/\epsilon \rfloor$. However, it could obviously be the case that after the installation of a ruler upgrade to ticklength $\epsilon'$ the newly measured length $x_{\epsilon'} \equiv n'\epsilon$, where $n' = \lfloor x^\star/\epsilon \rfloor$ would \emph{change} as it would be more accurate. Now, supposed the theorists of this world, what if we wanted a specification of a length that would encode the result of a measurement by a ruler with arbitrarily good (but still finite!) ticklength  $\epsilon > 0$ (infinite accuracy was frowned upon)? Well this was obvious: just specify all possible lengths by \emph{sequences} of successively more accurate lengths:
\begin{equation}
	(x_n)_{n \in \mathbb{N}}, \quad x_n\in \mathbb{Q}^+.
\end{equation}
Now not all sequences were allowed, only those which became more accurate as $n \rightarrow \infty$. That is, only those sequences $(x_\epsilon)_{n \in \mathbb{N}}$ enjoying the property that $\forall \epsilon, \exists N\in \mathbb{N}$ such that $\forall m,n\in \mathbb{N}$
\begin{equation}
	|x_n-x_m| < \epsilon,
\end{equation} 
where considered to correspond to a possible length. It was clear that all the originally accepted lengths $x\in \mathbb{Q}^+$ admitted the representation $(x_n)_{n\in \mathbb{N}}$, with $x_n = x$, so this new definition could accommodate the old one. The space of all these sequences was denoted $\widehat{\mathbb{R}}^+$. However, it was now possible that two apparently different sequences would correspond to the same length. This was solved by introducing the equivalence relation 
\begin{equation}
	(x_n)_{n \in \mathbb{N}} \sim (y_n)_{n \in \mathbb{N}} \Leftrightarrow \text{if $\forall \epsilon$, $\exists N\in \mathbb{N}$ such that $m,n>N$ it was true that $|x_n-y_n| < \epsilon$.} 
\end{equation}
Thus, the space of all possible lengths was defined to be $\mathbb{R}^+ \equiv \widehat{\mathbb{R}}^+/\sim$.

The story of how they discovered negative lengths must be told elsewhere...

Of course this fairy tale is just an allegory for the construction of the real numbers by the process of \emph{completion} of the rational numbers, whereby ``continuous'' things (i.e., elements of $\mathbb{R}$) are constructed by sequences of ``not-so-continuous'' things (i.e., the positive ratioanl numbers)

Let's isolate two key features of this allegory. Firstly, we have the space of ``not-so-continuous'' \emph{regularised} objects which specify objects with \emph{finite accuracy}. Secondly, we have a way to talk about the \emph{precision}, by understanding when two objects are effectively \emph{indistinguishable}. We then build the continuous objects as sequences of finite-accuracy objects modulo the equivalence relation that two such sequences represent the same object if they are indistinguishable for all accuracies.

\subsection{What a field state is}
By analogy with the construction of the rational numbers in the previous section we now describe how to define a \emph{quantum field state}. What we need 
\begin{enumerate} 
	\item Define a set $\mathcal{F}$ \red{[that symbol was already used for something else. shouldn't it be $S_{\rm reg}$?]} of \emph{regularised} field states which specify the field state to some finite accuracy (these states are analogous to the positive rationals $\mathbb{Q}^+$); and
	\item define \emph{accuracy}, i.e., a way of saying if two regularised field states $\rho$ and $\rho'$ are effectively indistinguishable given certain idealised experimental limitations specified by a list of numbers, called \emph{resolutions}, $r \equiv (\sigma, h, \ldots)$. (This requirement is analogous to writing $|x-y|<\epsilon$ for the positive rationals.)
\end{enumerate}


\section{Building Cauchy sequences: the renormalisation group}\label{sec:cauchyseqrg}

We've learnt that the building block of a quantum field state is a \emph{Cauchy sequence} of regulated quantum field states where we build a metric by insisting that the large-scale observable properties are close. This is all well and good but we now need to argue that such sequences exist. This is the task of this section where we argue that not only such sequences exist but also there are an embarrassment of riches of them. We then argue that this plentitude can cut down to a manageable size by imposing a simple hypothesis for their structure

Recall that our large-scale observables at scale $\sigma$ are determined in the Heisenberg picture by a CP map $\mathcal{E}_\sigma$ which acts by embedding or ``spreading out'' the observables across the UV degrees of freedom. In the Schr\"odinger picture this CP acts dually as $\mathcal{E}_\sigma^*$ where it is a \emph{coarse graining} map that essentially acts as a partial trace. Indeed, in the case of the hard momentum cutoff it is precisely a partial trace over the large momentum degrees of freedom.  Now, suppose we have some reduced density operator $\rho_\sigma$ from which we'd like to build a Cauchy sequence, i.e., from which we'd like to remove the UV regulator. To do this we need to ``put back in'' the state on the degrees of freedom between $\sigma$ and a UV cutoff $\Lambda$ in a way that would be consistent for all $\sigma < \Lambda$. This is the same as looking for a sequence $(\rho_{\Lambda_n})_{n=1}^\infty$ of states with the property that
\begin{equation}
\rho_{\Lambda_m} = \tr_{(\Lambda_m,\Lambda_n]}(\rho_{\Lambda_n}), \quad \Lambda_m < \Lambda_n.
\end{equation}
I.e., the state $\rho_{\Lambda_n}$ must be an \emph{extension} or, improperly, a \emph{purification}, of $\rho_{\Lambda_m}$ onto the larger bipartite system comprising the original interval $\Lambda_m$ and the complement of $\Lambda_m$ in $\Lambda_n$. Now there are an infinite number of extensions/purifications for any given state, so there are an infinite number of possible sequences. These are all Cauchy. In fact, even better, they are \emph{exactly} convergent sequences! 
What is happening here is that we are finding the \emph{inverse} of a many to one map (the coarse graining map $\mathcal{E}_\sigma$). Because the map is many to one there are, by definition, many inverses, each of which has every right to be called a UV completion or continuum limit. What an embarrassment of riches! 

We have every right to be dissatisfied and suspicious with the proposed solution above. As the astute reader will no doubt observe: the sequences $(\rho_{\Lambda_n})_{n=1}^\infty$ are not useful for physics because how could we ever decide which one is the correct one by doing experiments? Well, you know what, tough luck: to quote Polchinski, ``nobody ever promised you a rose garden''. This is just the way things are: it is simply the case that something bizarre and crazy could turn up at any moment in our particle accelerators as we upgrade them to access more an more observables. There is no mathematical proof that could ever exclude this possibility apart from our desire for the universe to be kind to us and be explainable. You just have to learn to live with this. 

The way we implement the constraint of ``explainability'' is to demand that our states are, at least in principle, \emph{parametrisable} in terms of a finite number of numbers, or \emph{coupling constants}. Traditionally this is carried 

\begin{center}
\includegraphics{rginverse.pdf}
\end{center}



We then define a \emph{field state} to be a sequence\footnote{More generally we'll need to specify field states by \emph{nets} $\phi_\Lambda \in \mathcal{F}$, $\Lambda\in\mathbb{R}^+$.} $\phi_n\in\mathbb{F}$, $n\in\mathbb{N}$, of field states such that for all values of the resolution parameters $r$, $\exists N\in \mathbb{N}$ such that $\forall m,n > N$ the states $\phi_m$ and $\phi_n$ are effectively indistinguishable at resolution $r$. Thus we have come to the idea of a \emph{Cauchy sequence} of regularised field states. The process of finding a Cauchy sequence, i.e., of building a sequence such that $\phi_n$ is Cauchy, is known as the \emph{renormalisation group}.

\section{Discussion}\label{sec:discussion}




\bibliography{What-is-a-quantum-field-state}

%\appendix


\end{document}  


