%\documentclass[twocolumn,lengthcheck,superscriptaddress]{revtex4-1}

\documentclass[11pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epstopdf}
\usepackage{mathrsfs}
\usepackage{enumerate}
\usepackage{xypic}
\usepackage[shortalphabetic]{amsrefs}


\newcommand{\red}[1]{\textcolor{red}{#1}}

\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\vspan}{span}
\DeclareMathOperator{\res}{res}

\theoremstyle{plain}% default
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{corollary}{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}

%\bibliographystyle{amsalpha}

\title{What is a quantum field state?}
\date{\today}                                           % Activate to display a given date or no date


\begin{document}

\begin{abstract} 
There has recently been in a fruitful interplay of ideas between quantum information theory and high energy physics, especially in the context of quantum simulation, the AdS/CFT correspondence, and the black hole information loss paradox. However, a core difficulty faced by quantum information theorists -- who are usually concerned with qubits -- interested in these emergent and vibrant areas is the necessity of dealing with quantum fields. The primary purpose of these notes is to lower the entry barrier for quantum information theorists to work on such exciting and challenging topics by explaining what, in a quantum information friendly way, a quantum field state actually is. We describe the Wilsonian formulation of quantum field theory as an effective theory and explain how this leads naturally to a definition, independent of lagrangians, of quantum field states which is better adapted to, e.g., tensor networks. We hope that there is something here for high-energy theorists as well, if only to see how someone from ``the other side'' thinks about complex quantum systems.
\end{abstract}

\maketitle

\section{Introduction}
Quantum field theory (QFT) has become, thanks in no small part to Wilson 
\cite{wilson_renormalization_1974,wilson_renormalization_1975}, an immensely powerful calculational machine to solve and approximate a wide variety of physical problems from the fundamental physics of particles \cite{peskin_introduction_1995,weinberg_quantum_1996,weinberg_quantum_1996-1,weinberg_quantum_2000} to the effective description of many body interacting quantum systems such as magnets and dilute atomic gases \cite{fradkin_field_2013}. Thus it is no real exaggeration to say that QFT is the calculus of modern physics \cite{witten_surface_2006,seiberg_nathan_2014}. In contrast to the mature status that calculus enjoys, however, QFT is still far from a stable formulation \cite{howard_georgi_particles_2012,moore_physical_2014,seiberg_nathan_2014} as texts on the subject are not standardised and, further,  mathematicians are not yet universally happy with QFT as practiced by physicists. 

Amongst the many formulations of QFT, a most popular one is in terms of \emph{lagrangians}. Here one begins with a set of \emph{classical} equations of motion, encapsulated by a lagrangian via the principle of least action \cite{arnold_mathematical_1989}, and then one seeks a \emph{quantisation} of these equations of motion, typically via the path integral prescription. This approach has led to great progress: for example, it works extremely well in the perturbative setting, where quantum field theory is now on a rather firm footing and, more importantly, it also provides an elegant way to approach the \emph{nonperturbative} setting where, e.g., it serves as the basis of lattice gauge theory \cite{creutz_quarks_1985,wilson_confinement_1974}. In the case of lattice gauge theory a dramatic validation of the path integral formulation was recently obtained when the hadronic spectrum of QCD was numerically obtained from first principles \cite{durr_ab_2008}. However, despite the power and ubiquity of the lagrangian/path integral approach, there are still many mysteries concerning nonperturbative QFT.  

One way to make progress on understanding nonperturbative QFT might be to eschew the lagrangian parametrisation altogether. This is not a new idea: in the '60s and '70s the idea of deriving all of physics from the analyticity properties \cite{eden_analytic_2002} of the $S$ matrix was very popular. This idea lost steam\footnote{This is actually not fair: the $S$ matrix bootstrap programme was one of the starting points for string theory, which has subsequently enjoyed tremendous success in understanding QFT, especially via dualities. This is a vast topic which lies beyond the scope of these notes. Here we largely focus on non-string approaches to QFT.} in the late '70s in the wake of the stunning success of the standard model. Recently, however, there has been an upswing in interest in formulations of QFT without the lagrangian. A major impetus here comes from string theory \cite{moore_physical_2014,howard_georgi_particles_2012} where there are arguments that there exists certain quantum field theories \cite{witten_comments_1995,moore_lecture_2012} with no known, or no unique, lagrangian. Additional motivation for studying QFT without lagrangians has been powerfully articulated by Arkani-Hamed and collaborators in the course of the programme to understanding the scattering amplitudes for $\mathcal{N}=4$ supersymmetric Yang-Mills theory \cite{arkani-hamed_what_2010,arkani-hamed_into_2014,arkani-hamed_tree_2008,arkani-hamed_scattering_2012,arkani-hamed_all-loop_2011,arkani-hamed_amplituhedron_2014,arkani-hamed_s-matrix_2010,arkani-hamed_what_2010}: here the core motivation is to find a parametrisation of QFT which exposes hidden symmetries at the expense of  manifest unitarity and locality, i.e., to allow spacetime to be an emergent property.  

The theme of emergent spacetime plays a crucial role in discussions of the \emph{holographic principle} \cite{bousso_holographic_2002}. In the specific context of the AdS/CFT correspondence \cite{maldacena_large_1999} we have seen that spacetimes of certain associated bulk degrees of freedom are encoded into the hilbert spaces of strongly interacting quantum many body systems living on spatial boundaries. The nature of this encoding is still not completely understood, particularly away from the large-$N$ limit where semiclassical arguments are no longer valid. However, this idea has proved to be so deep that even just taking aim at its general direction has lead to spectacular and exciting progress. Most relevant for this paper is a line of enquiry beginning with the work of Swingle \cite{swingle_entanglement_2012} applying tensor networks to quantify the nature of, and the correspondence between, bulk and boundary degrees of freedom \cite{nozaki_holographic_2012,ryu_aspects_2006,ryu_holographic_2006}. Also closely related, are studies exploiting quantum information theoretic ideas, particularly from the study of quantum error correcting codes \cite{almheiri_bulk_2014} and quantum Shannon theory \cite{czech_information_2014}, aimed at elucidating the interpretation of AdS/CFT duality. These recent studies usually work by first discretisating the problem and then deploying the apparatus of quantum information theory to the resulting discrete system. The precise way in which results obtained in this way survive the limit to the continuum is rather subtle.

Continuing with the themes of holography, emergent spacetime geometry, and quantum information theory, there has been a recent flurry of activity centred around the ``firewall'' paradox, initiated by the work of \cite{almheiri_black_2013}. The ensuing debate has prompted many intriguing and original ideas aimed at resolving the paradox. One extremely suggestive proposal \cite{maldacena_cool_2013}, known as ``ER=EPR'', posits that the fabric of spacetime itself is none other than quantum entanglement. This is heady stuff! However it is hard, especially for the quantum information theorist, to make concrete sense of it, especially since at first sight, the proposal appears to be a category error. 

We believe that quantum information theorists have interesting things to contribute to high energy physics and see several possibilities. The most direct way would be to develop ideas and results that have already proved successful in the study of strongly correlated complex quantum systems to apply to settings of direct interest in high energy physics. In condensed matter physics inspiration from quantum information theory has led to the development of new variational families of \emph{tensor network states} (TNS), including, the \emph{projected entangled pair states} (PEPS) \cite{verstraete_renormalization_2004} and the \emph{multiscale entanglement renormalisation ansatz} (MERA) \cite{vidal_entanglement_2007,vidal_class_2008}. The crucial idea underlying these developments is that TNS provide a parsimonious and expressive \emph{data structure} to parametrise  the hilbert space of physical states naturally arising \cite{poulin_quantum_2011} in local quantum systems \cite{orus_practical_2014, haegeman_geometry_2014,osborne_simulating_2007,bravyi_topological_2010,bravyi_short_2011,hastings_lieb-schultz-mattis_2004,hastings_area_2007,osborne_efficient_2006}. One way to carry out the goal of understanding quantum fields via tensor network methods is to formulate TNS directly in the continuum. This approach has already given rise to the continuous matrix products states (cMPS) \cite{verstraete_continuous_2010,osborne_holographic_2010, haegeman_calculus_2013}, continuous PEPS \cite{jennings_variational_2012}, and continuous MERA classes \cite{haegeman_entanglement_2013}. Such continuous TNS have provided some new insights in the study of some problems in high-energy physics, and promise to provide a powerful way to reason about entangled quantum fields. Another way, adopted in this paper, is to simply understand how discrete TNS approximate a given QFT. This approach is easier to implement numerically, and also more directly allows the computation of, e.g., quantum entanglement.

Another avenue where quantum information theory seems likely to lead to progress in high energy physics is by exploiting quantum computers to directly simulate scattering processes. This is an important goal, even in the perturbative setting, because quantum computers allow the computation of scattering amplitudes involving many particles which require the summation of a prohibitive number of Feynman diagrams. Pursuit of this idea has led to the development of discrete quantum simulation algorithms for scalar field theory \cite{jordan_quantum_2012,jordan_quantum_2011} and the Gross-Neveu model on the lattice \cite{jordan_quantum_2014}. Here there are again fascinating questions about how to understand the nonperturbative regime and the approach to the continuum.  

Finally, and somewhat more speculatively, the work \cite{arkani-hamed_what_2010,arkani-hamed_into_2014,arkani-hamed_tree_2008,arkani-hamed_scattering_2012,arkani-hamed_all-loop_2011,arkani-hamed_amplituhedron_2014,arkani-hamed_s-matrix_2010,arkani-hamed_what_2010} of Arkani-Hamed and collaborators is rather suggestive to someone with a quantum information background: the idea that scattering amplitudes can be directly obtained from the volumes of a certain special convex set known as the \emph{amplituhedron} resonates strongly with themes that have been discussed in the quantum information literature. In particular, the amplituhedron bears a superficial resemblence to the convex set of reduced density operators for (translation invariant) complex quantum systems \cite{verstraete_matrix_2006,zauner_symmetry_2014}. For instance, one can argue that scattering amplitudes for any complex quantum system may be directly derived from knowledge of a related convex set \cite{osborne_tobiasosborne}. Whether the connection between these two topics is more than metaphoric is far from clear, however, it seems like a deep idea worth exploring further. 

So it seems that there are a variety of ways in which quantum information theory could contribute to high energy theory. However, there is a fundamental difficulty facing the quantum information theorist, namely that quantum fields involve a continuous infinity of degrees of freedom. This setting is rather far removed from the home ground of quantum information theory, namely, the qubit. When faced with the insecurity of dealing with an unfamiliar setting it is very tempting to find a concrete rigourous mathematical formulation for the theory. In the case of quantum field theory the pursuit of a satisfying mathematical objective has sparked a remarkable variety of different approaches, invoking mathematics from the algebraic, probabilistic, to the geometric. It is not possible to do justice to this work here, but we are lucky in that we can simply refer to an excellent recent survey of Douglas \cite{douglas_foundations_2012}, who provides a broad overview of the existing approaches to a mathematical theory of QFT. It is certainly possible that one way quantum information theory could contribute to high energy physics is via one of the aforementioned mathematical approaches. However, we now end up with two problems, namely, understanding and developing quantum information ideas for a given mathematical approach, and then working out how to apply them to physical problems. 

The approach adopted in these notes is rather different. Here we advocate directly understanding QFT as practiced by physicists from a quantum information perspective. This differs in two important ways from existing mathematical approaches that have been so far developed. Firstly, we regard QFT as an effective theory and, secondly, we focus on quantum state space in addition to quantum observables. By simply understanding the way QFT is formulated as an effective theory, we can avoid a lot of heavy mathematical machinery and get down to concrete problems and calculations. 

So what is a quantum field state? Our answer, as we argue in the course of this paper, is that a quantum field state is simply a \emph{sequence of states} of discretised theories with a certain property, namely, that each term gets closer to each other (i.e., a \emph{Cauchy sequence}). This is directly analogous to how we study, via computer, classical fields, like fluids and gases and the electromagnetic field. Following in the footsteps of Wilson, we spend some time discussing how to measure ``closeness'', leading to the introduction of a family of quantum information distance measures quantifying the large-scale behaviour of a many particle state. 

We've structured this paper as follows. We begin in \S\ref{sec:opqp} with a short overview of operational quantum mechanics with an emphasis on density operators, completely positive maps, and POVMs. After setting up this basic language we move on in \S\ref{sec:quant} to a short overview of the problems of quantisation. Then we discuss in \S\ref{sec:whatisqft}, on a purely heuristic level, what a field theory really ought to be. With this motivation we then discuss effective theories in \S\ref{sec:effectivetheories}, which directly leads to the Wilsonian formulation of effective quantum field theory, reviewed in \S\ref{sec:wilson}. This discussion is then used as the direct motivation for our definition of effective quantum field states in \S\ref{sec:effectiveqftstates}. The construction of quantum field states via completion is then introduced in \S\ref{sec:qftcompletion}. The explanation of the renormalisation group as a means to construct Cauchy sequences of states is then described in \S\ref{sec:cauchyseqrg}. Finally, we conclude with some discussion and outlook in \S\ref{sec:discussion}.

\section{Operational quantum physics}\label{sec:opqp}
Throughout these notes we emphasise the \emph{operational} or \emph{modular}\footnote{Modular refers, in this context, to the idea that the primitive operations of preparation, evolution, and measurement may be composed arbitrarily to build \emph{quantum circuits}, much as we do in building classical circuits.} \emph{viewpoint}: here the focus is on physical quantities with an \emph{operational interpretation}, i.e., a physical quantity is considered operationally meaningful only if there exists, at least in principle, an experiment which could measure it. The modular viewpoint is common within quantum information theory as it lends itself very naturally to quantum circuits. The operational view also seems to mesh rather well with the Wilsonian view of QFT, where QFT is seen as an effective theory.

A convenient way to discuss quantum physics within the operational or modular viewpoint is via \emph{observables and effects}, \emph{density operators}, and \emph{completely positive maps} \cite{ludwig_foundations_1983,davies_quantum_1976}. This language may be unfamiliar to the reader and we pause a moment to review it here. Firstly, the way we characterise \emph{quantum} (indeed, also \emph{classical}) systems is via a set $\mathcal{A}$ of \emph{observables}. The observables typically form an algebra isomorphic to the bounded operators $\mathcal{B}(\mathcal{H})$ on some hilbert space $\mathcal{H}$, however this is not strictly necessary\footnote{The algebra structure is usually employed as a proxy for the positivity notion. All that we actually need is that $\mathcal{A}$ is an \emph{Archmidean Order Unit} (AOU) vector space \cite{paulsen_vector_2009,kleinmann_typical_2013}.} for there to be a probability interpretation. For the probability interpretation we need only require that $\mathcal{A}$ has a notion of \emph{positivity}, i.e., there is a cone $\mathcal{A}^+ \subset \mathcal{A}$ of positive elements and that there is a distinguished unit element $\mathbb{I}\in\mathcal{A}$ which is also positive. A good example to keep in mind here is that of the \emph{qubit}, where $\mathcal{A}\equiv M_2(\mathbb{C})$, the algebra of $2\times 2$ complex matrices and $\mathcal{A}^+ \equiv \{M\in \mathcal{A}\,|\, M\ge 0\}$ (with $\ge$ denoting the positive semidefinite order, i.e., $M\ge 0$ if and only if there exists $A\in \mathcal{A}$ such that $M = A^\dag A$). Another example is that of a \emph{classical} system, which is characterised by a \emph{commutative algebra} $\mathcal{A}\equiv \mathcal{C}(X)$, the set of functions from some set $X$ to $\mathbb{C}$; a \emph{classical bit} corresponds to the choice $X \equiv \{0,1\}$. An \emph{effect} $E\in\mathcal{A}^+$ is then what we call an observable corresponding to an \emph{outcome}, \emph{proposition}, \emph{predicate}, or \emph{yes/no measurement}. It is characterised by the property that $0\le E\le \mathbb{I}$. The unit element is the effect corresponding to empty predicate, that is, no assertion. For the qubit example above the projector $P_0 = \left(\begin{smallmatrix} 1 & 0 \\ 0 & 0\end{smallmatrix}\right)$ is the effect corresponding to the assertion that the system is in the ``zero'' configuration. A POVM\footnote{The acronym POVM stands for ``positive operator valued measure'', which takes its full meaning when the observable can take a continuous sets of values. } corresponds to a measurement of a system and---provided it can take only finitely many values---comprises of a set $\mathcal{M} = \{E_j\}_{j=1}^n$ of effects such that 
\begin{equation}
	\sum_{j=1}^n E_j = \mathbb{I}.
\end{equation}
The subscript label $j$ is what carries the information about what \emph{outcome} was observed when the measurement took place. It can be interpreted directly as the \emph{value} of the observable being measured, or simply as a label of that value. It is worth stressing that the effects $E_j$ need not be projections.  

Compositions of systems is described via the \emph{tensor product} operation: suppose we have two systems $A$ and $B$ characterised by the observable sets $\mathcal{A}_A$ and $\mathcal{A}_B$, respectively. The joint system $AB$ is then characterised by the observable set $\mathcal{A}_{AB} \equiv \mathcal{A}_A\otimes \mathcal{A}_B$. This space allows the simultaneous observation of effects in both $\mathcal{A}_A$ \emph{and} $\mathcal{A}_B$. The \emph{classical composition} of two systems $\mathcal{A}_A$ and $\mathcal{A}_B$, where we allow the observations of effects in \emph{either}  $\mathcal{A}_A$ \emph{or} $\mathcal{A}_B$, i.e., our system is either of one type or another -- superpositions are not allowed -- is described by the \emph{direct sum} operation $\mathcal{A}_{A}\oplus \mathcal{A}_B$. This is the smallest space of effects allowing us to probabilistically measure an effect from  $\mathcal{A}_A$ or $\mathcal{A}_B$

A \emph{state} $\omega:\mathcal{A}\rightarrow \mathbb{C}$ on the observable set $\mathcal{A}$ is a \emph{positive}, \emph{normalised}, and \emph{linear} functional, i.e., $\omega:\mathcal{A}^+\rightarrow \mathbb{R}^+$ and $\omega(e) = 1$. A state describes a \emph{preparation} of the system, and captures all the information relevant for the statistical outcomes of measurements on the system. The probability $p_E$ that, after a measurement of a POVM $\mathcal{M}$, an outcome with corresponding effect $E$ occurs is given by $p_E = \omega(E)$. Usually in quantum information theory we work with finite-dimensional quantum systems with $\mathcal{A}\equiv M_d(\mathbb{C})$ so that we can represent states via \emph{density operators} $\rho\in M_d(\mathbb{C})$ according to $\omega(M) \equiv \tr(\rho M)$, with $\tr(\rho) = 1$, $\rho \ge 0$. (Be aware that in infinite-dimensional settings it is not always possible to find a density operator corresponding to a state as the trace condition can easily fail.) A state $\omega$ is \emph{pure} if it cannot be written as a convex combination of other states, i.e., if $\omega \not= p \omega' + (1-p) \omega''$, with $p\in (0,1)$. Continuing the qubit example from above we see that single-qubit states $\omega$ correspond to $2\times 2$ density operators 
\begin{equation}
	\rho = \frac{\mathbb{I} + \mathbf{r}\cdot \boldsymbol{\sigma}}{2},  
\end{equation}  
with $\boldsymbol{\sigma} \equiv \left[\left(\begin{smallmatrix} 0 & 1 \\ 1 & 0\end{smallmatrix}\right), \left(\begin{smallmatrix} 0 & -i \\ i & 0\end{smallmatrix}\right), \left(\begin{smallmatrix} 1 & 0 \\ 0 & -1\end{smallmatrix}\right)\right]$. We have that $\omega(\sigma^j) = \tr(\rho \sigma^j)$. The condition that $\rho$ corresponds to a state translates to the condition that $|\mathbf{r}| \le 1$. Pure qubit states are precisely those with $|\mathbf{r}| = 1$.

The most general dynamical process that can occur within quantum mechanics is represented by a \emph{completely positive map} (CP map), or \emph{channel}. These processes describe everything from preparations, time evolutions, measurements, to the addition of ancilla and the discarding of subsystems. The input and output of a CP map may be arbitrary: there is no especial difficulty in the formulation caused by, e.g., different numbers of input and output systems. We first describe CP maps in the \emph{heisenberg picture} where modifications of measurements are specified. Here a CP map $\mathcal{E}$ is characterised by the following three axioms: 
\begin{enumerate}
	\item it is a \emph{linear} map $\mathcal{E}:\mathcal{A}_B\rightarrow \mathcal{A}_A$ from the observables $\mathcal{A}_B$ of an \emph{output system} $B$ to the observables of $\mathcal{A}_A$ of the  \emph{input system} $A$;
	\item the map $\mathcal{E}$ is \emph{positive}, i.e., it takes positive elements to positive elements according to $\mathcal{E}:\mathcal{A}_B^+\rightarrow \mathcal{A}_A^+$; and 
	\item running the map $\mathcal{E}$ in parallel with the \emph{identity channel} $\mathcal{I}_E : \mathcal{A}_E\rightarrow \mathcal{A}_E$ on an arbitrary auxiliary system $\mathcal{A}_E$ yields a positive linear map $\mathcal{E}\otimes \mathcal{I}_E$ from $\mathcal{A}_B\otimes \mathcal{A}_E$ to $\mathcal{A}_A\otimes \mathcal{A}_E$.
\end{enumerate} 
Pleasingly this axiomatic characterisation of a general dynamical process matches the following constructive characterisation. Suppose we only allow maps which comprise of the following three primitives: (1) adjunction of  ancillary systems; (2) unitary transformations; and (3) reduction to a subsystem. Then it is a result of Stinespring that such operations correspond precisely to CP maps and vice versa. 
\begin{theorem}[Stinespring] Suppose that $\mathcal{A}_A \equiv M_m(\mathbb{C})$ and $\mathcal{A}_B \equiv M_n(\mathbb{C})$. Then a linear map $\mathcal{E}:\mathcal{A}_B\rightarrow \mathcal{A}_A$ is completely positive if an only if there is an auxiliary system $\mathcal{A}_E \equiv M_l(\mathbb{C})$ such that it takes the form
\begin{equation}
	\mathcal{E}(X) = V^\dag (X\otimes \mathbb{I}_E) V,
\end{equation}
where $V$ is an operator from $\mathbb{C}^m$ to $\mathbb{C}^n\otimes\mathbb{C}^l$. Further, $V$ is an isometry whenever $\mathcal{E}$ is \emph{unital}, i.e., $\mathcal{E}(\mathbb{I}) = \mathbb{I}$. 
\end{theorem}
Here $V$ describes both the unitary dynamics and the reduction to a subsystem and $X\mapsto X\otimes \mathbb{I}$ describes the adjunction of the ancillary system. 

There are several key examples of CP maps naturally arising in physics.  The first example are the so-called \emph{cq channels} (cq = classical-quantum), describing \emph{preparations}: these are channels from a set of quantum observables $\mathcal{A}$ to classical observables $\mathcal{C}(X)$ with $X \equiv \{1,2,\ldots, n\}$,
\begin{equation}
	\mathcal{E}(E) \equiv \sum_{j = 1}^n \omega_j (E) \delta_j,
\end{equation}
where $\{\omega_j\}_1^{n}$ are a set of states on $\mathcal{A}$, and $\delta_j$ is the delta function on $\{1,2,\ldots, n\}$, i.e., $\delta_j(k) = \delta_{jk}$. 

The second important subclass of channels are those describing \emph{evolutions} according to \emph{unitary dynamics}: these CP maps are nothing more that conjugation by a unitary operator $U$
\begin{equation}
	\mathcal{U}(X) \equiv U^\dag X U.
\end{equation}

The final essential example of a channel is the \emph{qc channel} describing a POVM measurement
\begin{equation}
	\mathcal{M}(\delta_j) \equiv E_j.
\end{equation}

Using channels we can expose the modular structure of general processes in quantum mechanics, where components can be combined and concatenated: we draw classical information with a double line and quantum states with a single line. The passage of time is thought of as flowing from left to right. Channels are represented as boxes with input and output lines. Accordingly, any experiment in physics ultimately corresponds to the combination of a preparation, an evolution, and a measurement. We represent this pictorially represented as follows.
\begin{center}
\includegraphics{prepevolvemeasure.pdf}
\end{center}
Here, conditioned on a classical input with the value $j$ a quantum state $\rho_j$ is prepared. This is subsequently evolved according to a completely positive map $\mathcal{E}$. Finally a POVM measurement $\mathcal{M} = \{E_k\}$ is performed producing the classical output $k$. Although this modular view of quantum mechanics won't be directly exploited in the sequel, it is present in our minds when we come to discussing the building blocks of quantum field theory. 


Thus, from now on, when we say the word ``theory'' we take this to mean the specification of a triple $(\mathcal{A}, \mathcal{E}_t, \omega)$ of an observable set $\mathcal{A}$, a family of CP maps $\mathcal{E}_t: \mathbb{R}\times\mathcal{A}\rightarrow \mathcal{A}$ of possible evolutions, and a preparation $\omega$. We think of $\mathcal{A}$ as the space of \emph{equal-time} observables. The channel $\mathcal{E}_t$ is what implements the operation of translation in \emph{time}\footnote{In the case where the theory admits an action of a larger group $G$ of, say, spacetime translations, or Poincar\'e transformations, we then suppose that $\mathcal{E}_g$ is indexed by elements of $g\in G$.}. It is convenient to exploit the shorthand notation $A(t) \equiv \mathcal{E}_t(A)$. Thus we can now discuss observables corresponding to measurements at different times. In the case where $\mathcal{A}$ has an algebraic structure\footnote{In the case where $\mathcal{A}$ does not have an algebraic structure we have to explicitly describe correlation functions via instruments.} this allows us to introduce the observables corresponding to $n$-point correlation functions, namely, 
\begin{equation}
	A_1^\dag(t_1)A_2^\dag(t_2)\cdots A_n^\dag(t_n)A_n(t_n) \cdots A_2(t_2)A_1(t_1),
\end{equation} 
where $A_j(t_j) \in \mathcal{A}$, $j= 1,2, \ldots, n$. If $\omega$ is a state represented with density operator $\rho$ on $\mathcal{A}$ the resulting correlator is
\begin{multline}
	\langle A_1^\dag(t_1)A_2^\dag(t_2)\cdots A_n^\dag(t_n)A_n(t_n) \cdots A_2(t_2)A_1(t_1) \rangle =\\ \tr( A_n(t_n) \cdots A_2(t_2)A_1(t_1)\rho A_1^\dag(t_1) A_2^\dag(t_2) \cdots A_n^\dag(t_n)).
\end{multline}
This correlator may be implemented via postselection on the instrument carrying out the measurement of $A_j(t_j)$. 
Note that a ``standard'' $n$-point correlation function $\langle A_n(t_n) \cdots A_2(t_2)A_1(t_1) \rangle$ is not directly measurable in quantum mechanics as, in general, the product $A_n(t_n) \cdots A_2(t_2)A_1(t_1)$ is not even hermitian. Instead, such correlators must be inferred from scattering \cite{taylor_scattering_2006} or interference experiments \cite{glauber_quantum_1963,mandel_optical_1995}.

\section{Quantisation isn't a mystery, it's an inverse problem}\label{sec:quant}
Before we get started with understanding quantum field states we pause a moment to stress a simple yet important point. The universe didn't become quantum in 1927 at the Fifth Solvay International Conference, it has always been quantum. The reason that we didn't notice quantum effects for such a long time is because of \emph{decoherence} \cite{joos_decoherence_2003,gardiner_quantum_2010}, i.e., the unavoidable loss of quantum coherence due to uncontrolled interactions with unobservable environment degrees of freedom. In the presence of quantum noise pure unitary dynamics described by a unitary channel $\mathcal{U}_t$ obeying 
\begin{equation}
	\frac{d}{dt}\mathcal{U}_t(X) \equiv -i [H, \mathcal{U}_t(X)]
\end{equation}
is modified to a noisy CP map $\mathcal{E}_t$ generated by 
\begin{equation}
	\frac{d}{dt}\mathcal{E}_t(X) \equiv -i [H, \mathcal{E}_t(X)] -\frac12\sum_{\alpha=1}^m L_\alpha^\dag L_\alpha \mathcal{E}_t(X) + \mathcal{E}_t(X) L_\alpha^\dag L_\alpha - L_\alpha \mathcal{E}_t(X) L_\alpha^\dag
\end{equation}
which can, for quantum systems with a continuous degree of freedom (e.g., a particle on the line), be \emph{very effectively} modelled by a symplectic transformation on phase space. 
\begin{center}
\includegraphics{Decoherence.pdf}
\end{center}
The map, induced by decoherence, between a unitary quantum process and an effective classical process is extremely nonlinear and complicated. However, the most relevant feature of decoherence for this discussion is simply that many different quantum dynamical processes can be, after decoherence has set in, effectively modelled by the \emph{same} classical dynamical system. Thus the decoherence map is, amongst other things, a \emph{many to one} map. Thus, when presented with a given classical dynamical system we have no way, not even in principle, of identifying the ``correct'' quantisation; we are trying to invert a many to one map and there is no canonical choice of preimage.  None of this is really surprising or controversial. (Note that the \emph{semiclassical limit} is \emph{not} the same as the \emph{effective classical limit} arising from the presence of decoherence. While there is, in both cases, an emergence of classicality from a quantum system, the reasoning is totally different.)

Quantisation is hard precisely because we are trying to simultaneously solve more than one problem at once: we are trying to find a quantum system such that when we solve the system in the presence of decoherence, we find it is well described by a classical effective theory which matches the originally specified classical system. Said this way it is truly a miracle that the bewildering variety of quantisation recipes developed over the past decades work at all! 
\begin{center}
\includegraphics{Quantisation.pdf}
\end{center}
From this perspective it isn't so surprising that quantisation prescriptions aren't universal maps between classical systems and quantum systems, i.e., in mathematical language, \emph{functors}. This is an important observation because it is the first serious sign that there is some room to play with in finding quantum field theories: if we are looking for a quantum system with a specific effective classical description in the presence of decoherence there are many answers that will lead to equivalent results, giving us more room to find one with a useful parsimonious description. 

So how is the inverse problem of quantisation solved? A vitally important role guiding us toward a solution is played by \emph{symmetries}: if a desired classical limit is invariant under some group of symmetry operations then it is reasonable to assume that a good quantisation ought to furnish some representation of the same symmetry group (especially if the envisaged decoherence process leading to the classical limit is not expected to break the symmetry). This radically cuts down the search space we need to cover in looking for a quantisation. It can turn out, however, that the full symmetry group cannot be represented on a given quantisation, in which case we say that one or more symmetries are \emph{anomolous}. It is an interesting question whether, in general, anomolies disappear in the classical limit under a reasonable model of decoherence.

In the more modular language promoted in these notes we simply simplistically regard decoherence as a channel $\mathcal{D}$ that gets applied to our system before we perform our measurements. Thus, in the heisenberg picture, you can think of decoherence as modifying the effects we can measure to more noisy effects.  

\section{What is a field theory}\label{sec:whatisqft}
Let's now begin our discussion proper by contemplating, at a purely heuristic level, what a \emph{field theory} should be. On a purely intuitive level, a \emph{field} (either quantum or classical) is supposed to comprise of \emph{continuously} many degrees of freedom, i.e., roughly speaking, there is a degree of freedom for each point in space $\mathbb{R}^d$ (or spacetime $\mathbb{R}\times \mathbb{R}^d$). When dealing with such a vast abundance of degrees of freedom the task of just specifying a state of such a field becomes deeply nontrivial. 

Classically, this task can be largely thought of as being solved by calculus. Here \emph{pure field states} can be simply defined to be continuous functions $\phi:\mathbb{R}^d\rightarrow \mathbb{R}$. The space $C(\mathbb{R}^D)$ (or, in the case of spacetime, $C(\mathbb{R}\times\mathbb{R}^D)$) of all \emph{mathematically} possible such field states is rather wild: it is uncountably infinite. Worse, the task of understanding probability measures on such a space is deeply nontrivial, meaning that a statistical theory of classical fields is already extremely hard.

Of course, not all of the states in $C(\mathbb{R}^D)$ are meant to be physically realisable, i.e., we haven't yet specified the conditions a \emph{physical state} must satisfy. Classically this is done by requiring that physical pure states satisfy certain differential equations. For example, in a $(1+1)$-dimensional spacetime of points $(t,x)\in \mathbb{R}^2$ we could demand that valid physical states satisfy
\begin{equation}
	\frac{\partial^2\phi}{\partial t^2} - \frac{\partial^2\phi}{\partial x^2} + m^2\phi = 0.
\end{equation}
Just to be a solution of such an equation of motion implicitly requires that $\phi$ is at least twice differentiable. (Leaving aside, for the moment, the topic of weak solutions and distributions.) The condition of differentiability is actually rather nontrivial as it means that at small scales any solution is quite boring (it is basically a straight line) when we zoom in:
\begin{center}
\includegraphics{difffunc.pdf}
\end{center}
While this doesn't help us solve the problem of building statistical theories of classical fields, it does at least allow us to tame the problem of understanding pure states and their dynamics for systems of continuously many classical degrees of freedom. 

But what about quantum theories? Here we encounter a fundamentally new problem not present in the classical case: it is now hard to even define \emph{pure} field states. Naively this should be straightforward: just define the space of pure states to be the tensor product
\begin{equation}
	\mathcal{H}\, \text{``$=$''} \bigotimes_{x\in \mathbb{R}^d} \mathcal{H}_x,
\end{equation}
where $\mathcal{H}_x$ is the hilbert space for a single degree of freedom located at $x$. The scare quotes here are intended to indicate that the object on the right hand side does not \emph{naively} exist in any satisfying mathematical way\footnote{It does exist in a less naive way via von Neumann's incomplete tensor product. The incomplete tensor product admits an attractive physical intepretation: it is the separable hilbert space describing the configurations of at most a finite number of particles above the vacuum state. Finite can mean, e.g., $10^{34}$. This doesn't help us, however, as it just pushes our difficulties into building the vacuum.}. But let us be bold physicists for a moment and simply pretend that mathematicians will sort it all out and the space does exist. In this case we ought to have a basis of pure states labelled, e.g., by continuous functions
\begin{equation}
	\{|\phi\rangle \}_{\phi:\mathbb{R}^d\rightarrow \mathbb{R}}.
\end{equation}
While this initially looks reasonable we quickly see that there is a new difficulty: what superpositions are we going to allow? All of them? Surely not: we must find equations that specify for us the physically realisable states. Here we can no longer take recourse to calculus for help. Indeed, the problem of specifying physically realisable pure states of quantum fields is intimately tied to the problem of writing probability measures for classical fields in one lower spatial dimension via the so called ``classical-quantum'' correspondence where the path integral for a system in $D$ spatial dimensions can be regarded, via Wick rotation, as defining a statistical mechanical system in $D+1$ euclidean dimensions.

In both the classical statistical field and the quantum field cases we have come up against a fundamental physical problem (as opposed to a technical mathematical problem), namely that of specifying interesting states of fields (in the former case, as probability measures, and in the latter as pure states). What we ideally want is a physical principle that tells what are the ``good'', or \emph{physical}, field states versus the ``bad'', or \emph{unphysical}, states.  

\section{Effective field theories}\label{sec:effectivetheories}

 Suppose we have some extraordinarily complicated system of many particles: a good example to keep in mind is \emph{water}. Now if it were easy for us to make any conceivable measurement allowed by quantum mechanics of the system \emph{at no cost}, then there is \emph{no way} we'd be fooled into thinking water is anything other than a collection of a vast number of fundamental particles, quarks, gluons, etc., in some incredibly complicated evolving entangled state. The reason we don't see water like this is that we \emph{can't} make any measurement of the system without paying some kind of bill: the more complicated the measurement the more we have to pay. Thus we have to settle with making measurements of simpler quantities. For example, our eyes are basically a pair of pretty crappy photon detectors and thus when we look at a water sample we are simply carrying out a very noisy and inefficient POVM. Now here is the main point: when you only have access to a handful of observables then you can formulate a \emph{simpler hypothesis} which can still explain all the observational data you can obtain. This simpler hypothesis is an \emph{effective theory} for the system. Simpler here can mean many things, but in the context of this paper it is via a field theory\footnote{Why are fields simple? The answer is calculus: it is often easier to calculate integrals than sums.}.

A convenient way to model the large-scale degrees of freedom that we humans with our limited resources can access is by \emph{zooming out}. How can one, in general, implement the operation of ``zooming out''? Since zooming out corresponds to ignoring information the answer is via an irreversible CP map $\mathcal{E}$. The reason that it has to be irreversible is that it must prevent us from measuring degrees of freedom that we would otherwise be able to measure: after all, if we could measure all the observables after zooming out that we could measure before then in what sense can we be have said to have zoomed out? In the context of lattice systems there is a very convenient way to implement the zoom-out operation, namely, via Kadanoff blocking. This is the CP map whereby a block of spins is mapped to single spin via the partial trace channel, and then the lattice is rescaled.

Suppose we have some tremendously complicated microscopic system pertaining to degrees of freedom at some fundamental length scale $\Lambda$ in some state $\rho_\Lambda$. However, we can only perform limited measurements at our terrestrial length scale $\sigma$ modelled by effects of the form $\mathcal{E}_{\sigma}(E)$, where $E \in \mathcal{A}_{\sigma}$ is an effect in the space of \emph{our} observables. Since we can only measure a handful of all the possible observables $\mathcal{A}_\Lambda$ on the microscopic theory, we are satisfied with the explanation provided by any \emph{effective state} $\rho_{\text{eff}}$ which looks indistinguishable from $\rho_\Lambda$ according to any measurement $\mathcal{E}_{\sigma}(E)$, i.e.\ any state obeying
\begin{equation}
	\tr(\mathcal{E}_{\sigma}(E) (\rho_\Lambda - \rho_{\text{eff}})) \approx 0, \quad \text{for all } E\in \mathcal{A}_\sigma.
\end{equation}
The fewer the observables we can measure, the simpler we can take $\rho_{\text{eff}}$ to be. In the case of fields, we are only able to measure a handful of observables $E(x)$ indexed by some continuous label $x$; we'll explain this a bit more concretely in the following sections.

One aspect of this discussion may be puzzling for readers familiar with quantum field theories: why are we insisting on saying a change of scale is a lossy operation when, e.g., in CFTs a scale change is a \emph{reversible unitary operation}? The answer is that, in terms of a \emph{microscopic theory} with a cutoff, zooming out \emph{must} be a lossy operation as we can push degrees of freedom past the cutoff. However, in terms of an effective theory, a scale change can be unitary because there is an effective decoupling of the large-scale  and the small-scale degrees of freedom and the action of a finite scale change doesn't, \emph{in the large cutoff limit}, couple the different sets of degrees of freedom. 

A quantum information theorist may find the analogy with noiseless subsystems helpful: if you like, effective theories are analogous to (approximate) decoherence-free subspaces/subsystem codes, where the errors in this case are induced by scale changes. This is a quantitative way to understand what is meant by IR/UV decoupling. If zooming out is a CP map $\mathcal{E}$ then what is ``zooming in'', or \emph{UV completion}? The answer is that there is no unique answer: any CP map $\mathcal{D}$ such that $\mathcal{D}\circ \mathcal{E} \equiv \mathcal{I}$ can be given the interpretation as a zooming in map. Exploiting once more the analogy with noiseless subsystems you can think of zooming out as an error recovery operation $\mathcal{D}$ on the large-scale degrees of freedom. We will return to this point later.

\section{The Wilsonian formulation of effective quantum field theory}\label{sec:wilson}
Here we review, broadly following the expositions of \cite{wilson_renormalization_1975} and \cite{moore_lecture_2012}, the Wilsonian view of quantum field theory as an effective field theory. It is \emph{not at all} necessary to understand the discussion here at anything other than a metaphoric level as we are going to revisit the ideas of this section many times in the sequel to make the intuitive discussions here more concrete. Just read through the description and try and absorb the general flavour. 

In the Wilsonian formulation we begin with the space of observables/effects $\mathcal{A}_{\text{reg}}$ of \emph{regulated} or \emph{cutoff} quantum field theories\footnote{Remember: we always specify our theories in terms of observables.}. What are these? Well, there are an infinite number of ways to define them, but one you can keep in mind is by simply putting a theory on a lattice. It is important, at this stage, to emphasise that the regulated theories are the only ones which are expected to make mathematical sense. You can think of $\mathcal{A}_{\text{reg}}$ as the (direct sum of the) space of observables for all possible theories of bosons and fermions hopping on lattices with some \emph{nonzero} lattice spacing $a = 1/\Lambda$. (This way of defining a cutoff QFT is certainly not the most elegant, but it does enjoy considerable advantages for evaluation on a computer.) Thus $\mathcal{A}_{\text{reg}}$ can be thought of as the space of all lattice theories with nonzero lattice spacings: for each $\Lambda$ there is a subspace $\mathcal{A}_\Lambda$ corresponding to the observables/effects of lattice theories with a cutoff given by $\Lambda$, and these are all identified with their image in $\mathcal{A}_{\text{reg}}$ via some \emph{embedding} map $f_\Lambda:\mathcal{A}_\Lambda\rightarrow \mathcal{A}$. 

Once you have cut off a quantum field theory most, if not all, of the nasty divergences you've heard about disappear, and we only have to cope with more pedestrian divergences familiar to condensed matter physicists (e.g., the ``orthogonality catastrophe'' and ``infrared divergences''). 

One might be tempted to think that $\mathcal{A}_{\text{reg}}$ is already the space of observables of quantum field theories. However, this is really not the case: any observable/effect in the space $\mathcal{A}_{\text{reg}}$ corresponds, by construction, to an observable/effect for a lattice with a \emph{finite} cutoff $\Lambda$. This cutoff can be arbitrarily large but it must always be finite and thus there is always an underlying lattice structure (be it in momentum or position space or otherwise). A good analogy to keep in mind here is that between the rational numbers $\mathbb{Q}$ and the real numbers $\mathbb{R}$: any element of $\mathbb{Q}$ is expressible as $a/b$ with $a<\infty$ and $b < \infty$. However, something like $\sqrt{2}$ would need to be expressed as a rational number with infinitely large numerator and denominator, i.e., there are many numbers `missing' from $\mathbb{Q}$. 

Hence we now imagine that $\mathcal{A}_{\text{reg}}$ lives inside some even larger space $\mathcal{A}$ of ``all'' observables/effects of quantum field theories (whatever that might mean), with or without regulator. This is rather vague, but we argue below that we can ignore almost all the theories in $\mathcal{A}\setminus\mathcal{A}_{\text{reg}}$, as only a small fraction are \emph{physically relevant}.

Let's now construct a proper quantum field theory, i.e., a theory without cutoff. To do this suppose that for a particular given theory $(\mathcal{A}_\Lambda, \mathcal{E}_{t,\Lambda}, \omega_\Lambda)$ with observables $\mathcal{A}_\Lambda \subset \mathcal{A}_{\text{reg}}$ and cutoff $\Lambda$ we can always find a \emph{physically equivalent} theory $(\mathcal{A}_{\Lambda'}, \mathcal{E}_{t,\Lambda'}, \omega_{\Lambda'})$ with $\mathcal{A}_{\Lambda'} \subset \mathcal{A}_{\text{reg}}$ having a larger cutoff $\Lambda' > \Lambda$. If we can always do this then there is nothing stopping us sending the cutoff $\Lambda'\rightarrow \infty$ and calling the result a quantum field theory proper. Let's try and make this more concrete: what does it mean for a theory to have a larger cutoff than another theory? One clean operational interpretation is that all the \emph{effects} of our original theory can be found in the space of effects for the new theory with a larger cutoff. Thus, corresponding to the operation of changing cutoff from $\Lambda$ to $\Lambda' > \Lambda$, there must be a map
\begin{equation}
	\mathcal{F}_{\Lambda,\Lambda'}: \mathcal{A}_\Lambda \rightarrow \mathcal{A}_{\Lambda'}
\end{equation}
which identifies the effects of the lower-cutoff space with corresponding \emph{physically identical} effects in the higher-cutoff space. 
How do we determine this map? The standard answer is that the \emph{low-order correlation functions of large-scale low-energy observables} need to be preserved under the cutoff changing operation $\mathcal{F}_{\Lambda,\Lambda'}$. In other words: if we make a prediction for low-energy large-scale observables using a theory with cutoff $\Lambda$ then a \emph{physically equivalent} theory $\mathcal{A}_{\Lambda'}$ must give the same predictions for the original low-energy large scale observables. This map is not trivial to determine; this is where we need to do some physics!

Suppose we assume further that the dependence of $\mathcal{F}_{\Lambda,\Lambda'}$ is continuous, then we generate a \emph{flow} on $\mathcal{A}_{\text{reg}}$ (and hence on $\mathcal{A}$) via the map
\begin{equation}
	f_\Lambda\circ \mathcal{F}_{\Lambda,\Lambda'}\circ f_\Lambda^{-1}   
\end{equation}   
according to the diagram
\begin{equation}
\xymatrix{
\mathcal{A}_{\Lambda} \ar[rr]^{\mathcal{F}_{\Lambda,\Lambda'}}
\ar[dr]_{f_\Lambda}\hole
&& \mathcal{A}_{\Lambda'} \ar[dl]^{f_\Lambda'}\\
& \mathcal{A} }
\end{equation}
It is usually assumed  that that this flow on the infinite-dimensional space $\mathcal{A}$ is generated by a \emph{vector field}. A very special role is played by the \emph{fixed points} of this flow, as they correspond to genuine cutoff-free quantum field theories, i.e., theories of continuously many degrees of freedom. It is not at all obvious if $\mathcal{A}_{\text{reg}}$ contains any fixed points. This is an important observation, and it leads us closer to a resonable definition of $\mathcal{A}$ as the original space $\mathcal{A}_{\text{reg}}$ with missing points adjoined. Again the analogy with $\mathbb{Q}$ is helpful here: fixed points of well-defined maps on $\mathbb{Q}$ can easily fail to be in $\mathbb{Q}$, for example, consider $f(x) = x^2-1$: the fixed points of this map are $x_{\pm} = \frac{1\pm\sqrt{5}}{2}$. Thus we can tentatively think of $\mathcal{A}$ as the space of regulated theories with possibly missing fixed points of $\mathcal{F}_{\Lambda,\Lambda'}$ adjoined. It turns out that this picture is pretty close to the actual definition. Conformal field theories, being scale invariant, are then precisely fixed points.

It is standard to parametrise QFTs by \emph{local lagrangians}, which basically sort of amounts to a choice of a coordinate system for our mythical $\mathcal{A}$. Doing things this way tends to incentivise the  conflation of both states and effects into one object via the \emph{path integral}. The space $\mathcal{M}$ of lagrangians is an infinite-dimensional linear manifold with a coordinate for each local term you can add, e.g., 
\begin{equation}
	\mathcal{L} = c_0 + c_1\phi + c_2\phi^2 + c_3\phi^2 + \cdots + d_0 \phi \square \phi + d_1 \partial_\mu \phi \partial^\mu \phi +\cdots+ \text{etc.}
\end{equation}
Here a QFT is parametrised by the infinite list $(c_0, c_1, c_2, \ldots, d_0, d_1, \ldots, \text{etc.}) \in \mathbb{R}^\infty$. Lagrangians are, in combination with the path integral, a wonderfully compact way specify QFTs in a way that makes locality, causality, and symmetries such as Lorentz invariance manifest. However, they have the not inconsiderable downside that it is often very hard to compute correlation functions except perturbatively around special points.  

When we do things this way the maps $f_\Lambda$ and $\mathcal{F}_{\Lambda,\Lambda'}$ become \emph{diffeomorphisms} and the requirement that, after increasing the cutoff from $\Lambda$ to $\Lambda'$, the $n$-point correlation functions of large-scale low-energy observables remain invariant generates a deeply nontrivial \emph{renormalisation group} (RG) flow on the infinite dimensional manifold $\mathcal{M}$. 

The point of view taken in this paper is to describe how to apply the Wilsonian view to different, indeed arbitrary, ways of parametrising QFTs. A key step is to first separating out states and observables into separate categories.

As a crucial example, we'll show how to exploit \emph{tensor network states} to parametrise QFTs by implementing the continuum limit in the Wilsonian view directly on quantum states rather than lagrangians.


\section{Effective quantum field states and the Wilsonian formulation}\label{sec:effectiveqftstates}

We hereby attempt to formulate the most economical and conservative abstract interpretation of the Wilsonian view possible while preserving as much of the crucial physical structure as possible.

Casting an eye over the discussion in the previous section we isolate three core components:
\begin{enumerate}
	\item A space of observables $\mathcal{A}_{\text{reg}}$ for \emph{regulated} theories which are mathematically well behaved. The space $\mathcal{A}_{\text{reg}}$ is naturally parametrised with a \emph{cutoff} $\Lambda$, so that we can identify in $\mathcal{A}_{\text{reg}}$ the subspace $\mathcal{A}_{\Lambda}$ of theories with cutoff $\Lambda$.
	\item A way to \emph{compare} the predictions of two theories with \emph{different} cutoffs -- an \emph{information metric}.
	\item A way to identify the ``large-scale'' observables in $\mathcal{A}_{\text{reg}}$. It is only with respect to these observables that we actually compare two quantum field states.
\end{enumerate}  
As we argue below, once we've specified this ``minimal data'' we can exploit the Wilsonian view to define what is meant by a quantum field state.  
   

Once we've specified these three things we have enough information to define what is meant by a QFT. To motivate our eventual construction we first review the process of \emph{completion}.

\subsection{Regulated observables}

Two examples here: the lattice and momentum cutoff. Need to compare theories with different cutoff. ``Kadanoff'' as the answer. 


Before we begin our argument it is helpful to pause for a moment to digest the three core components of the Wilsonian view. Let's begin by discussing the space $\mathcal{A}_{\text{reg}}$ of regulated theories. What is this? It turns out that there is a large degree of arbitrariness here in the definition of $\mathcal{A}_{\text{reg}}$, depending on the choice of your favourite regulator. We can abstract away some of this by specifying some requirements. The key insight here is that we must have a \emph{partial order} on the way you regulate a theory. Here are two key examples: (a) the \emph{momentum-space regulator}, here we simply restrict all degrees of freedom to have momenta less than $\Lambda$. In this example the regulator is the cutoff $\Lambda$ -- note that there is a way to say that one cutoff is larger than another; (b) the \emph{lattice regulator}, which is given by a partition of space into a bunch of cells and we associate a degree of freedom with each cell. Here the regulator is specified by a \emph{partition} which, in the case of non regular discretisations, is no longer a simple number. However, there is still a \emph{partial order} on the space of partitions because there is a way to say that one partition is \emph{finer} than another. The abstract structure at play here is a bunch of mathematically well-defined theories $\mathcal{A}_\Lambda$ indexed by a set $I$ of ``cutoffs'' which has a \emph{partial order}. The space $\mathcal{A}_{\text{reg}}$ is then the smallest space which includes all of the effects $\mathcal{A}_\Lambda$, for all $\Lambda \in I$. If we don't have $\mathcal{A}_{\text{reg}}$ from the outset then we can always build it by taking the \emph{direct sum} of all the $\mathcal{A}_\Lambda$s and then identifying effects in all the different $\mathcal{A}_\Lambda$s which correspond to identical experiments (more on this later). Thus 
\begin{equation}
	\mathcal{A}_{\text{reg}} \equiv \left(\bigoplus_{\Lambda \in I} \mathcal{A}_\Lambda\right)\Bigg/\sim.
\end{equation} 
The space $\mathcal{A}_{\text{reg}}$ \emph{isn't yet} the space of QFTs\footnote{Following a suggestion of Witten, Moore calls $\mathcal{A}_{\text{reg}}$ the space of \emph{weak QFTs}, by analogy with the space of weak solutions to a PDE.}.


\subsection{Distance measures}

Review some QI distance measure stuff.


The next component we need to understand is how to \emph{compare} the predictions of two theories with differing cutoffs. This requires the specification of (a family of) \emph{distance measures} or \emph{information metrics}. This can be found by first agreeing on an operationally motivated distance measure on the \emph{state spaces} $\mathcal{S}_\Lambda$ of the $\mathcal{A}_\Lambda$s, and then extending this to the state space $\mathcal{S}_{\text{reg}}$ of all regulated states on $\mathcal{A}_{\text{reg}}$ in a way compatible with the equivalence relation $\sim$. This can be nontrivial; we'll discuss this at length in the following sections for the two important examples of the momentum cutoff and the lattice discretisation.


\subsection{Large-scale observables}


The final component is to specify the ``large-scale observables'' in $\mathcal{A}_{\text{reg}}$. This is done by specifying a \emph{completely positive map} $\mathcal{E}_\sigma : \mathcal{A}_{\text{reg}} \rightarrow \mathcal{A}_{\text{reg}}$, parametrised by one or more \emph{resolution} or \emph{scale parameters} $\sigma$, whose image is the convex set of all those effects measurable by large-scale observers (i.e., those measurement that we mere mortals can perform). 

\section{Two examples}

To illustrate the components of the Wilsonian formulation we'll specifically refer to two important examples 


\subsection{The momentum cutoff}
The class of examples is formulated in terms of

Key points to stress: we automatically have a way to compare two states with different cutoff.

\subsection{The real-space cutoff}
The real-space cutoff is implemented by putting the system on a lattice. In contrast to the momentum cutoff case we have a new problem: how to compare the states of two different lattices. 

\section{Quantum field states via completion}\label{sec:qftcompletion}
Let's tell a story about how physicists on a world far far away might have invented the real numbers $\mathbb{R}$.  The scientists of this world wanted to measure distances using rulers with tick marks spaced at regular intervals. On this world it was agreed that all rulers had to have their ticks spaced by fractions of some standard tick length $a_0$ (the length of the emperor's foot). Thus the tick spacing $\epsilon a_0$ of a ruler was required to be a positive rational ratio $\epsilon \in \mathbb{Q}^+$ of the standard tick length $a_0$. Owing to its canonical nature $a_0$ was set to $1$ by convention. To the scientists of this world all lengths were rational numbers. 

Now a scientist in possession of a ruler of accuracy $\epsilon$ would deem two lengths $x$ and $y$ differing by $\epsilon$ to be \emph{indistinguishable} (they rounded everything down on this world), i.e., two points $x$ and $y$ were \emph{$\epsilon$ equivalent} if
\begin{equation}
	x\sim_\epsilon y \Leftrightarrow |x-y| < \epsilon. 
\end{equation} 
For the longest time it was assumed that all lengths had rational values, after all, you could always build a better ruler to measure a length more accurately. 

However, one day it came to pass that a radical, clever, and sadly, unfortunate, scientist on this world made a shocking realisation: there could be a length $x^\star = \sqrt{2}$ which was \emph{not} exactly a rational number! Of course, this poor scientist was summarily executed (there is nothing worse than a smart ass). However, the argument gnawed at the minds of the conservative establishment for decades, and much hot air expended in coming to terms with it. Eventually, the inhabitants of this world came to the following construction. Obviously noone on the planet could measure the length $x_{\epsilon} = n\epsilon$ to be anything other than a multiple $n$ of the ticklength $\epsilon$ found from $n = \lfloor x^\star/\epsilon \rfloor$. However, it could obviously be the case that after the installation of a ruler upgrade to ticklength $\epsilon'$ the newly measured length $x_{\epsilon'} \equiv n'\epsilon$, where $n' = \lfloor x^\star/\epsilon \rfloor$ would \emph{change} as it would be more accurate. Now, supposed the theorists of this world, what if we wanted a specification of a length that would encode the result of a measurement by a ruler with arbitrarily good (but still finite!) ticklength  $\epsilon > 0$ (infinite accuracy was frowned upon)? Well this was obvious: just specify all possible lengths by \emph{sequences} of successively more accurate lengths:
\begin{equation}
	(x_n)_{n \in \mathbb{N}}, \quad x_n\in \mathbb{Q}^+.
\end{equation}
Now not all sequences were allowed, only those which became more accurate as $n \rightarrow \infty$. That is, only those sequences $(x_\epsilon)_{n \in \mathbb{N}}$ enjoying the property that $\forall \epsilon, \exists N\in \mathbb{N}$ such that $\forall m,n\in \mathbb{N}$
\begin{equation}
	|x_n-x_m| < \epsilon,
\end{equation} 
where considered to correspond to a possible length. It was clear that all the originally accepted lengths $x\in \mathbb{Q}^+$ admitted the representation $(x_n)_{n\in \mathbb{N}}$, with $x_n = x$, so this new definition could accommodate the old one. The space of all these sequences was denoted $\widehat{\mathbb{R}}^+$. However, it was now possible that two apparently different sequences would correspond to the same length. This was solved by introducing the equivalence relation 
\begin{equation}
	(x_n)_{n \in \mathbb{N}} \sim (y_n)_{n \in \mathbb{N}} \Leftrightarrow \text{if $\forall \epsilon$, $\exists N\in \mathbb{N}$ such that $m,n>N$ it was true that $|x_n-y_n| < \epsilon$.} 
\end{equation}
Thus, the space of all possible lengths was defined to be $\mathbb{R}^+ \equiv \widehat{\mathbb{R}}^+/\sim$.

The story of how they discovered negative lengths must be told elsewhere...

Of course this fairy tale is just an allegory for the construction of the real numbers by the process of \emph{completion} of the rational numbers, whereby ``continuous'' things (i.e., elements of $\mathbb{R}$) are constructed by sequences of ``not-so-continuous'' things (i.e., the positive ratioanl numbers)

Let's isolate two key features of this allegory. Firstly, we have the space of ``not-so-continuous'' \emph{regularised} objects which specify objects with \emph{finite accuracy}. Secondly, we have a way to talk about the \emph{precision}, by understanding when two objects are effectively \emph{indistinguishable}. We then build the continuous objects as sequences of finite-accuracy objects modulo the equivalence relation that two such sequences represent the same object if they are indistinguishable for all accuracies.

\subsection{What a field state is}
By analogy with the construction of the rational numbers in the previous section we now describe how to define a \emph{quantum field state}. What we need 
\begin{enumerate}
	\item Define a set $\mathcal{F}$ of \emph{regularised} field states which specify the field state to some finite accuracy (these states are analogous to the positive rationals $\mathbb{Q}^+$); and
	\item define \emph{accuracy}, i.e., a way of saying if two regularised field states $\rho$ and $\rho'$ are effectively indistinguishable given certain idealised experimental limitations specified by a list of numbers, called \emph{resolutions}, $r \equiv (\sigma, h, \ldots)$. (This requirement is analogous to writing $|x-y|<\epsilon$ for the positive rationals.)
\end{enumerate}


\section{Building Cauchy sequences: the renormalisation group}\label{sec:cauchyseqrg}

We've learnt that the building block of a quantum field state is a \emph{Cauchy sequence} of regulated quantum field states where we build a metric by insisting that the large-scale observable properties are close. This is all well and good but we now need to argue that such sequences exist. This is the task of this section where we argue that not only such sequences exist but also there are an embarrassment of riches of them. We then argue that this plentitude can cut down to a manageable size by imposing a simple hypothesis for their structure

Recall that our large-scale observables at scale $\sigma$ are determined in the Heisenberg picture by a CP map $\mathcal{E}_\sigma$ which acts by embedding or ``spreading out'' the observables across the UV degrees of freedom. In the Schr\"odinger picture this CP acts dually as $\mathcal{E}_\sigma^*$ where it is a \emph{coarse graining} map that essentially acts as a partial trace. Indeed, in the case of the hard momentum cutoff it is precisely a partial trace over the large momentum degrees of freedom.  Now, suppose we have some reduced density operator $\rho_\sigma$ from which we'd like to build a Cauchy sequence, i.e., from which we'd like to remove the UV regulator. To do this we need to ``put back in'' the state on the degrees of freedom between $\sigma$ and a UV cutoff $\Lambda$ in a way that would be consistent for all $\sigma < \Lambda$. This is the same as looking for a sequence $(\rho_{\Lambda_n})_{n=1}^\infty$ of states with the property that
\begin{equation}
\rho_{\Lambda_m} = \tr_{(\Lambda_m,\Lambda_n]}(\rho_{\Lambda_n}), \quad \Lambda_m < \Lambda_n.
\end{equation}
I.e., the state $\rho_{\Lambda_n}$ must be an \emph{extension} or, improperly, a \emph{purification}, of $\rho_{\Lambda_m}$ onto the larger bipartite system comprising the original interval $\Lambda_m$ and the complement of $\Lambda_m$ in $\Lambda_n$. Now there are an infinite number of extensions/purifications for any given state, so there are an infinite number of possible sequences. These are all Cauchy. In fact, even better, they are \emph{exactly} convergent sequences! 
What is happening here is that we are finding the \emph{inverse} of a many to one map (the coarse graining map $\mathcal{E}_\sigma$). Because the map is many to one there are, by definition, many inverses, each of which has every right to be called a UV completion or continuum limit. What an embarrassment of riches! 

We have every right to be dissatisfied and suspicious with the proposed solution above. As the astute reader will no doubt observe: the sequences $(\rho_{\Lambda_n})_{n=1}^\infty$ are not useful for physics because how could we ever decide which one is the correct one by doing experiments? Well, you know what, tough luck: to quote Polchinski, ``nobody ever promised you a rose garden''. This is just the way things are: it is simply the case that something bizarre and crazy could turn up at any moment in our particle accelerators as we upgrade them to access more an more observables. There is no mathematical proof that could ever exclude this possibility apart from our desire for the universe to be kind to us and be explainable. You just have to learn to live with this. 

The way we implement the constraint of ``explainability'' is to demand that our states are, at least in principle, \emph{parametrisable} in terms of a finite number of numbers, or \emph{coupling constants}. Traditionally this is carried 

\begin{center}
\includegraphics{rginverse.pdf}
\end{center}



We then define a \emph{field state} to be a sequence\footnote{More generally we'll need to specify field states by \emph{nets} $\phi_\Lambda \in \mathcal{F}$, $\Lambda\in\mathbb{R}^+$.} $\phi_n\in\mathbb{F}$, $n\in\mathbb{N}$, of field states such that for all values of the resolution parameters $r$, $\exists N\in \mathbb{N}$ such that $\forall m,n > N$ the states $\phi_m$ and $\phi_n$ are effectively indistinguishable at resolution $r$. Thus we have come to the idea of a \emph{Cauchy sequence} of regularised field states. The process of finding a Cauchy sequence, i.e., of building a sequence such that $\phi_n$ is Cauchy, is known as the \emph{renormalisation group}.

\section{Discussion}\label{sec:discussion}




\bibliography{What-is-a-quantum-field-state}

%\appendix


\end{document}  


